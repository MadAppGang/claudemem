/**
 * claudemem CLI
 *
 * Command-line interface for code indexing and search.
 */

import { existsSync, mkdirSync, readFileSync, readdirSync } from "node:fs";
import { dirname, join, relative, resolve } from "node:path";
import { createHash } from "node:crypto";
import { fileURLToPath } from "node:url";
import inquirerSearch from "@inquirer/search";
import { confirm, input, select } from "@inquirer/prompts";
import {
	ENV,
	getAnthropicApiKey,
	getApiKey,
	getEmbeddingModel,
	getLLMSpec,
	getVoyageApiKey,
	hasApiKey,
	isVectorEnabled,
	loadGlobalConfig,
	saveGlobalConfig,
} from "./config.js";
// Note: createIndexer imports store.js which loads LanceDB - made lazy to avoid startup errors
// Use: const { createIndexer } = await import("./core/indexer.js");
import { createEmbeddingsClient, getModelContextLength, truncateForModel } from "./core/embeddings.js";
import { chunkFileByPath, canChunkFile } from "./core/chunker.js";
// Note: createVectorStore is imported lazily to avoid loading LanceDB on startup
// Use: const { createVectorStore } = await import("./core/store.js");
import { createRepoMapGenerator } from "./core/repo-map.js";
import { createReferenceGraphManager } from "./core/reference-graph.js";
import { FileTracker } from "./core/tracker.js";
import {
	CURATED_PICKS,
	discoverEmbeddingModels,
	formatModelInfo,
	RECOMMENDED_MODELS,
} from "./models/model-discovery.js";
import {
	type AgentRole,
	VALID_ROLES,
	getInstructions,
	getCompactInstructions,
	listRoles,
} from "./ai-instructions.js";
import {
	CLAUDEMEM_SKILL,
	CLAUDEMEM_SKILL_COMPACT,
	CLAUDEMEM_MCP_SKILL,
	CLAUDEMEM_QUICK_REF,
	getFullSkillWithRole,
	getCompactSkillWithRole,
} from "./ai-skill.js";
import {
	getLogo,
	printLogo as printLogoUI,
	formatElapsed,
	createBenchmarkProgress,
	renderTable,
	renderSummary,
	renderHeader,
	renderInfo,
	renderSuccess,
	renderError,
	truncate,
	formatPercent,
	formatDuration,
	formatCost,
	formatContextLength,
	getHighlight,
	type TableColumn,
	type CellValue,
} from "./ui/index.js";

// ============================================================================
// Version & Branding
// ============================================================================

const __dirname = dirname(fileURLToPath(import.meta.url));
const packageJson = JSON.parse(
	readFileSync(join(__dirname, "../package.json"), "utf-8"),
);
const VERSION = packageJson.version;

/** Print logo for interactive commands */
function printLogo(): void {
	if (!noLogo) {
		printLogoUI();
	}
}

/** Global flag to suppress logo */
let noLogo = false;

// ============================================================================
// CLI Entry Point
// ============================================================================

export async function runCli(args: string[]): Promise<void> {
	// Parse global flags first
	if (args.includes("--nologo")) {
		noLogo = true;
		args = args.filter((a) => a !== "--nologo");
	}

	// Parse command
	const command = args[0];

	// Handle global flags
	if (args.includes("--version") || args.includes("-v")) {
		console.log(`claudemem version ${VERSION}`);
		return;
	}

	if (args.includes("--help") || args.includes("-h") || !command) {
		printHelp();
		return;
	}

	// Handle --models as global flag
	if (args.includes("--models")) {
		const remainingArgs = args.filter((a) => a !== "--models");
		await handleModels(remainingArgs);
		return;
	}

	// Route to command handler
	switch (command) {
		case "index":
			await handleIndex(args.slice(1));
			break;
		case "search":
			await handleSearch(args.slice(1));
			break;
		case "status":
			await handleStatus(args.slice(1));
			break;
		case "clear":
			await handleClear(args.slice(1));
			break;
		case "init":
			await handleInit();
			break;
		case "models":
			await handleModels(args.slice(1));
			break;
		case "benchmark":
			await handleBenchmark(args.slice(1));
			break;
		case "benchmark-llm":
			await handleBenchmarkLLM(args.slice(1));
			break;
		case "benchmark-llm-v2":
			await handleBenchmarkLLMv2(args.slice(1));
			break;
		case "benchmark-list":
			await handleBenchmarkList(args.slice(1));
			break;
		case "benchmark-show":
			await handleBenchmarkShow(args.slice(1));
			break;
		case "ai":
			handleAiInstructions(args.slice(1));
			break;
		// Symbol graph commands for AI agents
		case "map":
			await handleMap(args.slice(1));
			break;
		case "symbol":
			await handleSymbol(args.slice(1));
			break;
		case "callers":
			await handleCallers(args.slice(1));
			break;
		case "callees":
			await handleCallees(args.slice(1));
			break;
		case "context":
			await handleContext(args.slice(1));
			break;
		// Code analysis commands
		case "dead-code":
			await handleDeadCode(args.slice(1));
			break;
		case "test-gaps":
			await handleTestGaps(args.slice(1));
			break;
		case "impact":
			await handleImpact(args.slice(1));
			break;
		// Developer experience commands
		case "watch":
			await handleWatch(args.slice(1));
			break;
		case "hooks":
			await handleHooks(args.slice(1));
			break;
		default:
			// Check if it looks like a search query
			if (!command.startsWith("-")) {
				await handleSearch(args);
			} else {
				console.error(`Unknown command: ${command}`);
				console.error('Run "claudemem --help" for usage information.');
				process.exit(1);
			}
	}
}

// ============================================================================
// Command Handlers
// ============================================================================

// Note: formatElapsed and createBenchmarkProgress are imported from ./ui/index.js

/** Animation frames for indexing progress (local copy for createProgressRenderer) */
const INDEX_ANIM_FRAMES = ["â–“", "â–’", "â–‘", "â–’"];

/** Phase state for parallel phase tracking */
interface PhaseState {
	completed: number;
	total: number;
	inProgress: number;
	detail: string;
	startTime: number;
	isComplete: boolean;
	/** Frozen duration when phase completes (ms) */
	finalDuration?: number;
}

/** Create a progress renderer with support for parallel phases */
function createProgressRenderer() {
	const globalStartTime = Date.now();
	let animFrame = 0;
	let interval: ReturnType<typeof setInterval> | null = null;
	let linesWritten = 0; // Track how many lines we've actually rendered

	// Track multiple phases simultaneously (for parallel execution)
	const phases = new Map<string, PhaseState>();
	// Order phases appeared (for consistent rendering order)
	const phaseOrder: string[] = [];

	function renderLine(elapsed: string, bar: string, percent: number, phase: string, detail: string) {
		return `â± ${elapsed} â”‚ ${bar} ${percent.toString().padStart(3)}% â”‚ ${phase.padEnd(16)} â”‚ ${detail}`;
	}

	function buildBar(completed: number, total: number, inProgress: number) {
		const width = 20;
		const filledRatio = total > 0 ? completed / total : 0;
		const inProgressRatio = total > 0 ? inProgress / total : 0;

		const filledWidth = Math.round(filledRatio * width);
		const inProgressWidth = Math.min(Math.round(inProgressRatio * width), width - filledWidth);
		const emptyWidth = width - filledWidth - inProgressWidth;

		const filled = "â–ˆ".repeat(filledWidth);
		let animated = "";
		for (let i = 0; i < inProgressWidth; i++) {
			const charIndex = (animFrame + i) % INDEX_ANIM_FRAMES.length;
			animated += INDEX_ANIM_FRAMES[charIndex];
		}
		const empty = "â–‘".repeat(emptyWidth);
		return filled + animated + empty;
	}

	function render() {
		animFrame = (animFrame + 1) % INDEX_ANIM_FRAMES.length;

		// Move cursor up to redraw only the lines we previously wrote
		if (linesWritten > 0) {
			process.stdout.write(`\x1b[${linesWritten}A`);
		}

		// Render each phase in order
		for (const phaseName of phaseOrder) {
			const phase = phases.get(phaseName)!;
			const percent = phase.total > 0 ? Math.round((phase.completed / phase.total) * 100) : 0;
			const bar = phase.isComplete
				? "â–ˆ".repeat(20)
				: buildBar(phase.completed, phase.total, phase.inProgress);
			// Use frozen duration for completed phases, live duration for active
			const elapsed = phase.isComplete && phase.finalDuration !== undefined
				? formatElapsed(phase.finalDuration)
				: formatElapsed(Date.now() - phase.startTime);
			const detail = phase.isComplete ? "done" : phase.detail;

			process.stdout.write(`\r${renderLine(elapsed, bar, percent, phaseName, detail)}\x1b[K\n`);
		}

		// Render total line
		const totalElapsed = formatElapsed(Date.now() - globalStartTime);
		process.stdout.write(`\r\x1b[2mâ± ${totalElapsed} total\x1b[0m\x1b[K\n`);

		// Track how many lines we wrote (phases + total line)
		linesWritten = phaseOrder.length + 1;
	}

	return {
		start() {
			interval = setInterval(render, 100);
			if (interval.unref) interval.unref();
		},
		update(completed: number, total: number, detail: string, inProgress = 0) {
			// Match phase names including spaces, e.g. [file summaries]
			const phaseMatch = detail.match(/^\[([^\]]+)\]/);
			const phaseName = phaseMatch ? phaseMatch[1] : "processing";
			const cleanDetail = detail.replace(/^\[[^\]]+\]\s*/, "");

			// Create or update phase
			if (!phases.has(phaseName)) {
				phases.set(phaseName, {
					completed: 0,
					total: 0,
					inProgress: 0,
					detail: "",
					startTime: Date.now(),
					isComplete: false,
				});
				phaseOrder.push(phaseName);
			}

			const phase = phases.get(phaseName)!;

			// Only update if not already complete (don't regress)
			if (!phase.isComplete) {
				phase.completed = completed;
				phase.total = total;
				phase.inProgress = inProgress;
				phase.detail = cleanDetail;

				// Mark complete when 100% and no in-progress items
				if (completed >= total && total > 0 && inProgress === 0) {
					phase.isComplete = true;
					// Freeze the elapsed time
					phase.finalDuration = Date.now() - phase.startTime;
				}
			}
		},
		stop() {
			if (interval) {
				clearInterval(interval);
				interval = null;
			}
		},
		finish() {
			this.stop();

			// Mark all phases as complete with frozen durations
			for (const phase of phases.values()) {
				if (!phase.isComplete) {
					phase.finalDuration = Date.now() - phase.startTime;
				}
				phase.isComplete = true;
				phase.completed = phase.total;
				phase.inProgress = 0;
			}

			// Final render - use linesWritten to avoid overwriting unrelated lines
			animFrame = 0;
			if (linesWritten > 0) {
				process.stdout.write(`\x1b[${linesWritten}A`);
			}

			for (const phaseName of phaseOrder) {
				const phase = phases.get(phaseName)!;
				const elapsed = formatElapsed(phase.finalDuration ?? (Date.now() - phase.startTime));
				const bar = "â–ˆ".repeat(20);
				process.stdout.write(`\r${renderLine(elapsed, bar, 100, phaseName, "done")}\x1b[K\n`);
			}

			const totalElapsed = formatElapsed(Date.now() - globalStartTime);
			process.stdout.write(`\r\x1b[2mâ± ${totalElapsed} total\x1b[0m\x1b[K\n`);

			// Update linesWritten for consistency
			linesWritten = phaseOrder.length + 1;
		},
	};
}

async function handleIndex(args: string[]): Promise<void> {
	// Parse arguments
	const force = args.includes("--force") || args.includes("-f");
	const noLlm = args.includes("--no-llm") || args.includes("--no-enrichment");
	const forceUnlock = args.includes("--force-unlock");
	const wait = args.includes("--wait") || args.includes("-w");
	const pathArg = args.find((a) => !a.startsWith("-"));
	const projectPath = pathArg ? resolve(pathArg) : process.cwd();

	// Parse concurrency (default 10 for parallel LLM requests)
	const concurrencyArg = args.find((a) => a.startsWith("--concurrency="));
	const concurrency = concurrencyArg ? parseInt(concurrencyArg.split("=")[1], 10) : 10;

	// Parse wait timeout (default 5 minutes)
	const waitTimeoutArg = args.find((a) => a.startsWith("--wait-timeout="));
	const waitTimeout = waitTimeoutArg
		? parseInt(waitTimeoutArg.split("=")[1], 10) * 1000
		: 5 * 60 * 1000;

	// Handle force unlock
	if (forceUnlock) {
		const { createIndexer } = await import("./core/indexer.js");
		const indexer = createIndexer({ projectPath });
		const released = indexer.forceUnlock();
		if (released) {
			console.log("âœ… Lock released successfully.");
		} else {
			console.log("â„¹ï¸  No lock file found.");
		}
		return;
	}

	// Check if vector mode is enabled
	const vectorEnabled = isVectorEnabled(projectPath);

	// Check for API key (not needed when vector mode is disabled)
	if (vectorEnabled && !hasApiKey()) {
		console.error("Error: OpenRouter API key not configured.");
		console.error("Run 'claudemem init' to set up, or set OPENROUTER_API_KEY.");
		process.exit(1);
	}

	// Get model info for display
	const embeddingModel = getEmbeddingModel(projectPath);
	const llmSpec = getLLMSpec(projectPath);

	console.log(`\nIndexing ${projectPath}...`);
	if (vectorEnabled) {
		console.log(`  Embedding model: ${embeddingModel}`);
	} else {
		console.log(`  Vector mode: disabled (BM25 keyword search only)`);
	}
	if (!noLlm) {
		console.log(`  LLM for enrichment: ${llmSpec.displayName}`);
	}
	if (force) {
		console.log("(Force mode: re-indexing all files)");
	}
	if (noLlm) {
		console.log("(LLM enrichment disabled)");
	} else {
		console.log(`(Enrichment: ${concurrency} parallel requests)`);
	}
	console.log("");

	// Create progress renderer with continuous timer and animation
	const progress = createProgressRenderer();
	let waitingMessageShown = false;

	const { createIndexer, IndexLockError } = await import("./core/indexer.js");
	const indexer = createIndexer({
		projectPath,
		enableEnrichment: !noLlm,
		enrichmentConcurrency: concurrency,
		lockOptions: wait ? { waitTimeout } : undefined,
		onWaitingForLock: (holderPid, waitedMs) => {
			if (!waitingMessageShown) {
				console.log(`â³ Waiting for another indexing process (PID ${holderPid}) to finish...`);
				waitingMessageShown = true;
			}
		},
		onProgress: (current, total, file, inProgress) => {
			if (!progress) return;
			progress.update(current, total, file, inProgress ?? 0);
		},
	});

	// Start progress only after we know we have the lock
	progress.start();

	try {
		const result = await indexer.index(force);

		// Show final state and stop progress renderer
		progress.finish();

		const totalElapsed = formatElapsed(result.durationMs);
		console.log(`âœ… Indexing complete in ${totalElapsed}!\n`);
		console.log(`  Files indexed:  ${result.filesIndexed}`);
		console.log(`  Chunks created: ${result.chunksCreated}`);
		console.log(`  Duration:       ${(result.durationMs / 1000).toFixed(2)}s`);
		if (result.cost !== undefined) {
			console.log(`  Cost:           $${result.cost.toFixed(6)}`);
		}

		// Show enrichment results if available
		if (result.enrichment) {
			console.log(`\n  Enrichment:`);
			console.log(`    Documents:    ${result.enrichment.documentsCreated}`);

			// Show LLM calls and cost
			if (result.enrichment.llmCalls) {
				const { fileSummaries, symbolSummaries, total } = result.enrichment.llmCalls;
				const provider = result.enrichment.llmProvider;

				// For subscription/local providers, show "Subscription" or "Free" instead of cost
				if (provider === "claude-code") {
					console.log(`    LLM calls:    ${total} (Subscription)`);
					console.log(`      - file summaries:   ${fileSummaries} calls`);
					console.log(`      - symbol summaries: ${symbolSummaries} calls`);
				} else if (provider === "local") {
					console.log(`    LLM calls:    ${total} (Free - local)`);
					console.log(`      - file summaries:   ${fileSummaries} calls`);
					console.log(`      - symbol summaries: ${symbolSummaries} calls`);
				} else if (result.enrichment.cost !== undefined) {
					console.log(`    LLM cost:     $${result.enrichment.cost.toFixed(6)} (${total} calls)`);
					if (result.enrichment.costBreakdown) {
						const breakdown = result.enrichment.costBreakdown;
						if (breakdown.fileSummaries !== undefined) {
							console.log(`      - file summaries:   $${breakdown.fileSummaries.toFixed(6)} (${fileSummaries} calls)`);
						}
						if (breakdown.symbolSummaries !== undefined) {
							console.log(`      - symbol summaries: $${breakdown.symbolSummaries.toFixed(6)} (${symbolSummaries} calls)`);
						}
					}
				} else {
					console.log(`    LLM calls:    ${total}`);
					console.log(`      - file summaries:   ${fileSummaries} calls`);
					console.log(`      - symbol summaries: ${symbolSummaries} calls`);
				}
			}

			if (result.enrichment.errors.length > 0) {
				console.log(`    Errors:       ${result.enrichment.errors.length}`);
			}
		}

		if (result.errors.length > 0) {
			console.log(`\nâš ï¸  Errors (${result.errors.length}):`);
			for (const err of result.errors.slice(0, 5)) {
				console.log(`  - ${err.file}: ${err.error}`);
			}
			if (result.errors.length > 5) {
				console.log(`  ... and ${result.errors.length - 5} more`);
			}
		}
	} catch (error) {
		progress.stop();

		if (error instanceof IndexLockError) {
			console.error(`\nâŒ ${error.message}`);
			process.exit(1);
		}

		throw error;
	} finally {
		progress.stop();
		await indexer.close();
	}
}

async function handleSearch(args: string[]): Promise<void> {
	// Parse arguments
	const limitIdx = args.findIndex((a) => a === "-n" || a === "--limit");
	const limit =
		limitIdx >= 0 && args[limitIdx + 1]
			? parseInt(args[limitIdx + 1], 10)
			: 10;

	const langIdx = args.findIndex((a) => a === "-l" || a === "--language");
	const language = langIdx >= 0 ? args[langIdx + 1] : undefined;

	const pathIdx = args.findIndex((a) => a === "-p" || a === "--path");
	const projectPath = pathIdx >= 0 ? resolve(args[pathIdx + 1]) : process.cwd();

	// Embedding model override (will error if doesn't match stored model)
	const modelIdx = args.findIndex((a) => a === "-m" || a === "--model");
	const model = modelIdx >= 0 ? args[modelIdx + 1] : undefined;

	// Auto-index flags
	const noReindex = args.includes("--no-reindex");
	const autoYes = args.includes("-y") || args.includes("--yes");

	// Search use case (fim, search, navigation)
	const useCaseIdx = args.findIndex((a) => a === "--use-case");
	const useCase = useCaseIdx >= 0 ? args[useCaseIdx + 1] as "fim" | "search" | "navigation" : "search";

	// Keyword-only search (skip embedding API call, use BM25 only)
	const keywordOnly = args.includes("-k") || args.includes("--keyword");

	// Get query (everything that's not a flag)
	// Only add indices to flagIndices if the flag was actually found (>= 0)
	const flagIndices = new Set<number>();
	if (limitIdx >= 0) { flagIndices.add(limitIdx); flagIndices.add(limitIdx + 1); }
	if (langIdx >= 0) { flagIndices.add(langIdx); flagIndices.add(langIdx + 1); }
	if (pathIdx >= 0) { flagIndices.add(pathIdx); flagIndices.add(pathIdx + 1); }
	if (modelIdx >= 0) { flagIndices.add(modelIdx); flagIndices.add(modelIdx + 1); }
	if (useCaseIdx >= 0) { flagIndices.add(useCaseIdx); flagIndices.add(useCaseIdx + 1); }
	const queryParts = args.filter((_, i) => !flagIndices.has(i) && !args[i].startsWith("-"));
	const query = queryParts.join(" ");

	if (!query) {
		console.error("Error: No search query provided.");
		console.error('Usage: claudemem search "your query"');
		process.exit(1);
	}

	// Check if vector mode is enabled in config
	const vectorEnabled = isVectorEnabled(projectPath);

	// Check for API key (not needed for keyword-only search or when vector mode disabled)
	if (!keywordOnly && vectorEnabled && !hasApiKey()) {
		console.error("Error: OpenRouter API key not configured.");
		console.error("Run 'claudemem init' to set up, or set OPENROUTER_API_KEY.");
		process.exit(1);
	}

	const { createIndexer, EmbeddingModelMismatchError } = await import("./core/indexer.js");
	const indexer = createIndexer({ projectPath, model });

	try {
		// Check if index exists
		const status = await indexer.getStatus();

		if (!status.exists) {
			// No index - prompt to create or auto-create with -y
			if (autoYes) {
				console.log("\nNo index found. Creating initial index...\n");
			} else {
				const shouldIndex = await confirm({
					message: "No index found. Create initial index now?",
					default: true,
				});

				if (!shouldIndex) {
					console.log("Search cancelled. Run 'claudemem index' to create an index.");
					return;
				}
				console.log("");
			}

			// Create initial index
			const result = await indexer.index(false);
			console.log(`âœ… Indexed ${result.filesIndexed} files (${result.chunksCreated} chunks)\n`);
		} else if (!noReindex) {
			// Index exists - auto-reindex changed files with progress display
			// First, check if there are changes (quick check before showing progress)
			const progress = createProgressRenderer();
			let hasChanges = false;

			// Create a temporary indexer with progress callback
			const { createIndexer: createTempIndexer } = await import("./core/indexer.js");
			const tempIndexer = createTempIndexer({
				projectPath,
				onProgress: (current, total, detail, inProgress) => {
					if (!hasChanges && current > 0) {
						hasChanges = true;
						console.log("\nğŸ”„ Auto-reindexing changed files...\n");
						progress.start();
					}
					if (hasChanges) {
						progress.update(current, total, detail, inProgress ?? 0);
					}
				},
			});

			const result = await tempIndexer.index(false); // incremental

			if (hasChanges) {
				progress.finish();
				console.log(`âœ… Auto-indexed ${result.filesIndexed} changed file(s)\n`);
			}
		}

		console.log(`Searching for: "${query}"${keywordOnly ? " (keyword-only)" : ""}`);

		const results = await indexer.search(query, { limit, language, useCase, keywordOnly });

		if (results.length === 0) {
			console.log("\nNo results found.");
			console.log("Make sure the codebase is indexed: claudemem index");
			return;
		}

		console.log(`Found ${results.length} result(s):\n`);

		for (let i = 0; i < results.length; i++) {
			const r = results[i];
			const chunk = r.chunk;

			console.log(`â”â”â” ${i + 1}. ${chunk.filePath}:${chunk.startLine}-${chunk.endLine} â”â”â”`);
			console.log(`Type: ${chunk.chunkType}${chunk.name ? ` | Name: ${chunk.name}` : ""}${chunk.parentName ? ` | Parent: ${chunk.parentName}` : ""}`);
			console.log(`Score: ${(r.score * 100).toFixed(1)}% (vector: ${(r.vectorScore * 100).toFixed(0)}%, keyword: ${(r.keywordScore * 100).toFixed(0)}%)`);
			console.log("");

			// Print code with truncation
			const lines = chunk.content.split("\n");
			const maxLines = 20;
			const displayLines = lines.slice(0, maxLines);

			for (const line of displayLines) {
				console.log(`  ${line}`);
			}

			if (lines.length > maxLines) {
				console.log(`  ... (${lines.length - maxLines} more lines)`);
			}

			console.log("");
		}
	} catch (error) {
		if (error instanceof EmbeddingModelMismatchError) {
			console.error(`\nâŒ ${error.message}\n`);
			process.exit(1);
		}
		throw error;
	} finally {
		await indexer.close();
	}
}

async function handleStatus(args: string[]): Promise<void> {
	if (!noLogo) printLogo();

	const pathArg = args.find((a) => !a.startsWith("-"));
	const projectPath = pathArg ? resolve(pathArg) : process.cwd();

	const { createIndexer } = await import("./core/indexer.js");
	const indexer = createIndexer({ projectPath });

	try {
		const status = await indexer.getStatus();

		if (!status.exists) {
			console.log("\nNo index found for this project.");
			console.log("Run 'claudemem index' to create one.");
			return;
		}

		console.log("\nğŸ“Š Index Status\n");
		console.log(`  Path: ${projectPath}`);
		console.log(`  Files: ${status.totalFiles}`);
		console.log(`  Chunks: ${status.totalChunks}`);
		console.log(`  Languages: ${status.languages.join(", ") || "none"}`);
		if (status.embeddingModel) {
			console.log(`  Embedding model: ${status.embeddingModel}`);
		}
		if (status.lastUpdated) {
			console.log(`  Last updated: ${status.lastUpdated.toISOString()}`);
		}
	} finally {
		await indexer.close();
	}
}

async function handleClear(args: string[]): Promise<void> {
	if (!noLogo) printLogo();

	const pathArg = args.find((a) => !a.startsWith("-"));
	const projectPath = pathArg ? resolve(pathArg) : process.cwd();

	const force = args.includes("--force") || args.includes("-f");

	if (!force) {
		const confirmed = await confirm({
			message: `Clear index for ${projectPath}?`,
			default: false,
		});

		if (!confirmed) {
			console.log("Cancelled.");
			return;
		}
	}

	const { createIndexer } = await import("./core/indexer.js");
	const indexer = createIndexer({ projectPath });

	try {
		await indexer.clear();
		console.log("\nâœ… Index cleared.");
	} finally {
		await indexer.close();
	}
}

async function handleInit(): Promise<void> {
	if (!noLogo) printLogo();

	console.log("ğŸ”§ Setup\n");

	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	// STEP 1: Embedding Provider
	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	console.log("â”€â”€â”€ Embedding Configuration â”€â”€â”€\n");

	const embeddingProvider = await select({
		message: "Select embedding provider:",
		choices: [
			{
				name: "Voyage AI (recommended, best quality)",
				value: "voyage",
			},
			{
				name: "OpenRouter (cloud API, many models)",
				value: "openrouter",
			},
			{
				name: "Ollama (local, free)",
				value: "ollama",
			},
			{
				name: "LM Studio (local, OpenAI-compatible)",
				value: "lmstudio",
			},
			{
				name: "Custom endpoint (local HTTP server)",
				value: "local",
			},
		],
	}) as "voyage" | "openrouter" | "ollama" | "lmstudio" | "local";

	let embeddingModel: string;
	let embeddingEndpoint: string | undefined;
	let voyageApiKey: string | undefined;
	let openrouterApiKey: string | undefined;

	if (embeddingProvider === "voyage") {
		// Voyage AI setup
		const existingKey = getVoyageApiKey();
		if (existingKey) {
			const useExisting = await confirm({
				message: "Voyage API key already configured. Keep it?",
				default: true,
			});
			if (!useExisting) {
				voyageApiKey = await promptForVoyageApiKey();
			}
		} else {
			voyageApiKey = await promptForVoyageApiKey();
		}

		embeddingModel = await select({
			message: "Select Voyage embedding model:",
			choices: [
				{ name: "voyage-3.5-lite (recommended, fast, cheap)", value: "voyage-3.5-lite" },
				{ name: "voyage-3 (highest quality)", value: "voyage-3" },
				{ name: "voyage-code-3 (optimized for code)", value: "voyage-code-3" },
			],
		});

	} else if (embeddingProvider === "openrouter") {
		// OpenRouter setup
		const existingKey = getApiKey();
		if (existingKey) {
			const useExisting = await confirm({
				message: "OpenRouter API key already configured. Keep it?",
				default: true,
			});
			if (!useExisting) {
				await promptForApiKey();
			}
		} else {
			await promptForApiKey();
		}

		// Select OpenRouter model
		console.log("\nğŸ“¦ Fetching available models...\n");
		const models = await discoverEmbeddingModels();

		embeddingModel = await inquirerSearch({
			message: "Choose embedding model:",
			source: async (term: string | undefined) => {
				const filtered = term
					? models.filter(
							(m) =>
								m.id.toLowerCase().includes(term.toLowerCase()) ||
								m.name.toLowerCase().includes(term.toLowerCase()),
						)
					: models.slice(0, 10);

				return filtered.map((m) => ({
					name: formatModelInfo(m),
					value: m.id,
				}));
			},
		});

	} else if (embeddingProvider === "ollama") {
		// Ollama setup
		embeddingEndpoint = await input({
			message: "Ollama endpoint URL:",
			default: "http://localhost:11434",
		});

		// Test connection
		console.log("\nğŸ”„ Testing Ollama connection...");
		try {
			const response = await fetch(`${embeddingEndpoint}/api/tags`);
			if (response.ok) {
				const data = await response.json() as { models?: Array<{ name: string }> };
				const installedModels = data.models || [];
				const embModels = installedModels.filter((m: { name: string }) =>
					m.name.includes("embed") || m.name.includes("nomic") || m.name.includes("minilm") || m.name.includes("bge")
				);

				if (embModels.length > 0) {
					console.log(`âœ… Found ${embModels.length} embedding model(s)`);
					embeddingModel = await select({
						message: "Select embedding model:",
						choices: embModels.map((m: { name: string }) => ({
							name: m.name,
							value: m.name.replace(":latest", ""),
						})),
					});
				} else {
					console.log("âš ï¸  No embedding models found.");
					console.log("   Run: ollama pull nomic-embed-text");
					embeddingModel = "nomic-embed-text";
				}
			} else {
				throw new Error("Connection failed");
			}
		} catch {
			console.log("âš ï¸  Could not connect to Ollama. Make sure it's running.");
			embeddingModel = await input({
				message: "Enter embedding model name:",
				default: "nomic-embed-text",
			});
		}

	} else if (embeddingProvider === "lmstudio") {
		// LM Studio setup (OpenAI-compatible API)
		embeddingEndpoint = await input({
			message: "LM Studio endpoint URL:",
			default: "http://localhost:1234/v1",
		});

		// Test connection and list embedding models
		console.log("\nğŸ”„ Fetching LM Studio embedding models...");
		const models = await fetchLMStudioModels(embeddingEndpoint, "embedding");

		if (models.length > 0) {
			console.log(`âœ… Found ${models.length} embedding model(s)`);
			embeddingModel = await select({
				message: "Select embedding model:",
				choices: models.map((m) => ({
					name: `${m.id}${m.publisher ? ` (${m.publisher})` : ""}`,
					value: m.id,
				})),
			});
		} else {
			console.log("âš ï¸  No embedding models found in LM Studio.");
			console.log("   Make sure LM Studio is running and has embedding models loaded.");
			embeddingModel = await input({
				message: "Enter embedding model name:",
				default: "text-embedding-nomic-embed-text-v1.5",
			});
		}

	} else {
		// Custom endpoint setup
		embeddingEndpoint = await input({
			message: "Custom endpoint URL:",
			default: "http://localhost:8000",
		});
		embeddingModel = await input({
			message: "Model name:",
			default: "all-minilm-l6-v2",
		});
	}

	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	// STEP 2: LLM Enrichment
	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	console.log("\nâ”€â”€â”€ LLM Enrichment Configuration â”€â”€â”€\n");
	console.log("LLM enrichment generates semantic summaries for better search.\n");

	const enableEnrichment = await confirm({
		message: "Enable LLM enrichment?",
		default: true,
	});

	let llmSpec: string | undefined;
	let anthropicApiKey: string | undefined;

	if (enableEnrichment) {
		const llmProvider = await select({
			message: "Select LLM provider for enrichment:",
			choices: [
				{ name: "Claude Code CLI (uses your subscription)", value: "claude-code" },
				{ name: "Anthropic API (direct, requires API key)", value: "anthropic" },
				{ name: "OpenRouter (many models)", value: "openrouter" },
				{ name: "LM Studio (local, OpenAI-compatible)", value: "lmstudio" },
				{ name: "Ollama (local)", value: "ollama" },
			],
		});

		if (llmProvider === "claude-code") {
			const llmModel = await select({
				message: "Select Claude model:",
				choices: [
					{ name: "Claude Sonnet (recommended, balanced)", value: "sonnet" },
					{ name: "Claude Haiku (fastest, cheapest)", value: "haiku" },
					{ name: "Claude Opus (highest quality)", value: "opus" },
				],
			});
			llmSpec = `cc/${llmModel}`;

		} else if (llmProvider === "anthropic") {
			const existingAnthropicKey = getAnthropicApiKey();
			if (existingAnthropicKey) {
				const useExisting = await confirm({
					message: "Anthropic API key already configured. Keep it?",
					default: true,
				});
				if (!useExisting) {
					anthropicApiKey = await input({
						message: "Enter your Anthropic API key:",
						validate: (v) => v.startsWith("sk-ant-") || "Invalid format. Keys start with 'sk-ant-'",
					});
				}
			} else {
				anthropicApiKey = await input({
					message: "Enter your Anthropic API key:",
					validate: (v) => v.startsWith("sk-ant-") || "Invalid format. Keys start with 'sk-ant-'",
				});
			}

			const llmModel = await select({
				message: "Select Claude model:",
				choices: [
					{ name: "Claude Sonnet 4 (recommended)", value: "claude-sonnet-4-20250514" },
					{ name: "Claude Haiku 3.5 (fastest)", value: "claude-3-5-haiku-20241022" },
					{ name: "Claude Opus 4", value: "claude-opus-4-20250514" },
				],
			});
			llmSpec = `a/${llmModel}`;

		} else if (llmProvider === "openrouter") {
			// Reuse OpenRouter key if already set
			if (!getApiKey()) {
				console.log("\nâš ï¸  OpenRouter API key needed for LLM.");
				await promptForApiKey();
			}

			llmSpec = await input({
				message: "Enter OpenRouter model (e.g., openai/gpt-4o, anthropic/claude-3.5-sonnet):",
				default: "anthropic/claude-3.5-sonnet",
			});
			llmSpec = `or/${llmSpec}`;

		} else if (llmProvider === "lmstudio") {
			// LM Studio for LLM enrichment
			const lmstudioEndpoint = await input({
				message: "LM Studio endpoint URL:",
				default: "http://localhost:1234/v1",
			});

			// Fetch LLM models (llm and vlm types)
			console.log("\nğŸ”„ Fetching LM Studio LLM models...");
			const models = await fetchLMStudioModels(lmstudioEndpoint, "llm");

			let localModel: string;
			if (models.length > 0) {
				console.log(`âœ… Found ${models.length} LLM model(s)`);
				localModel = await select({
					message: "Select LLM model:",
					choices: models.map((m) => ({
						name: `${m.id}${m.publisher ? ` (${m.publisher})` : ""}`,
						value: m.id,
					})),
				});
			} else {
				console.log("âš ï¸  No LLM models found in LM Studio.");
				console.log("   Make sure LM Studio is running and has LLM models loaded.");
				localModel = await input({
					message: "Enter LLM model name:",
					default: "llama-3.2-3b-instruct",
				});
			}
			llmSpec = `lmstudio/${localModel}`;

		} else if (llmProvider === "ollama") {
			// Ollama for LLM enrichment
			const ollamaEndpoint = await input({
				message: "Ollama endpoint URL:",
				default: "http://localhost:11434",
			});

			// Test connection and list models
			console.log("\nğŸ”„ Testing Ollama connection...");
			try {
				const response = await fetch(`${ollamaEndpoint}/api/tags`);
				if (response.ok) {
					const data = await response.json() as { models?: Array<{ name: string }> };
					const installedModels = data.models || [];

					if (installedModels.length > 0) {
						console.log(`âœ… Found ${installedModels.length} model(s)`);
						const localModel = await select({
							message: "Select LLM model:",
							choices: installedModels.map((m: { name: string }) => ({
								name: m.name,
								value: m.name.replace(":latest", ""),
							})),
						});
						llmSpec = `ollama/${localModel}`;
					} else {
						console.log("âš ï¸  No models found. Run: ollama pull llama3.2");
						const localModel = await input({
							message: "Enter model name:",
							default: "llama3.2",
						});
						llmSpec = `ollama/${localModel}`;
					}
				} else {
					throw new Error("Connection failed");
				}
			} catch {
				console.log("âš ï¸  Could not connect to Ollama. Make sure it's running.");
				const localModel = await input({
					message: "Enter model name:",
					default: "llama3.2",
				});
				llmSpec = `ollama/${localModel}`;
			}
		}
	}

	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	// Save Configuration
	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	saveGlobalConfig({
		embeddingProvider: embeddingProvider === "lmstudio" ? "lmstudio" : embeddingProvider,
		defaultModel: embeddingModel,
		...(voyageApiKey ? { voyageApiKey } : {}),
		...(openrouterApiKey ? { openrouterApiKey } : {}),
		...(anthropicApiKey ? { anthropicApiKey } : {}),
		...(embeddingProvider === "ollama" && embeddingEndpoint ? { ollamaEndpoint: embeddingEndpoint } : {}),
		...(embeddingProvider === "lmstudio" && embeddingEndpoint ? { lmstudioEndpoint: embeddingEndpoint } : {}),
		...(embeddingProvider === "local" && embeddingEndpoint ? { localEndpoint: embeddingEndpoint } : {}),
		enableEnrichment,
		...(llmSpec ? { llm: llmSpec } : {}),
	});

	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	// Summary
	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	console.log("\nâœ… Setup complete!\n");
	console.log("â”€â”€â”€ Configuration Summary â”€â”€â”€\n");
	console.log(`  Embedding provider: ${embeddingProvider}`);
	console.log(`  Embedding model:    ${embeddingModel}`);
	if (embeddingEndpoint) console.log(`  Endpoint:           ${embeddingEndpoint}`);
	console.log(`  LLM enrichment:     ${enableEnrichment ? "enabled" : "disabled"}`);
	if (llmSpec) console.log(`  LLM model:          ${llmSpec}`);
	console.log("\nYou can now index your codebase:");
	console.log("  claudemem index\n");
}

interface LMStudioModel {
	id: string;
	type: string; // "llm" | "embeddings" | "vlm"
	publisher?: string;
	architecture?: string;
}

/**
 * Fetch available models from LM Studio
 * Uses the new API: http://localhost:1234/api/v0/models
 */
async function fetchLMStudioModels(
	endpoint: string,
	filter?: "embedding" | "llm",
): Promise<LMStudioModel[]> {
	try {
		// Use the new API endpoint
		const baseUrl = endpoint.replace(/\/v1\/?$/, ""); // Remove /v1 suffix if present
		const response = await fetch(`${baseUrl}/api/v0/models`);

		if (!response.ok) {
			return [];
		}

		const data = await response.json() as { data?: LMStudioModel[] };
		let models = data.data || [];

		// Filter by type if specified
		if (filter === "embedding") {
			models = models.filter((m) => m.type === "embeddings");
		} else if (filter === "llm") {
			models = models.filter((m) => m.type === "llm" || m.type === "vlm");
		}

		return models;
	} catch {
		return [];
	}
}

async function promptForVoyageApiKey(): Promise<string> {
	console.log("Voyage API key required for embeddings.");
	console.log("Get yours at: https://dash.voyageai.com/api-keys\n");

	const apiKey = await input({
		message: "Enter your Voyage API key:",
		validate: (value) => {
			if (!value.trim()) {
				return "API key is required";
			}
			if (!value.startsWith("pa-")) {
				return "Invalid format. Voyage keys start with 'pa-'";
			}
			return true;
		},
	});

	return apiKey;
}

async function handleModels(args: string[]): Promise<void> {
	if (!noLogo) printLogo();

	const freeOnly = args.includes("--free");
	const forceRefresh = args.includes("--refresh");
	const showOllama = args.includes("--ollama");

	// Colors for output
	const c = {
		reset: "\x1b[0m",
		bold: "\x1b[1m",
		dim: "\x1b[2m",
		cyan: "\x1b[36m",
		green: "\x1b[38;5;78m",
		yellow: "\x1b[33m",
		magenta: "\x1b[35m",
		orange: "\x1b[38;5;209m",
	};

	// Check current provider
	const config = loadGlobalConfig();
	const currentProvider = config.embeddingProvider || "openrouter";

	// Show Ollama models if requested or if using Ollama provider
	if (showOllama || currentProvider === "ollama") {
		console.log("\nğŸ“¦ Ollama Embedding Models\n");

		// Show recommended Ollama models
		console.log(`${c.orange}${c.bold}â­ RECOMMENDED OLLAMA MODELS${c.reset}\n`);

		const ollamaModels = [
			{ id: "nomic-embed-text", dim: 768, size: "274MB", desc: "Best quality, multilingual" },
			{ id: "mxbai-embed-large", dim: 1024, size: "670MB", desc: "Large context, high quality" },
			{ id: "all-minilm", dim: 384, size: "46MB", desc: "Fastest, lightweight" },
			{ id: "snowflake-arctic-embed", dim: 1024, size: "670MB", desc: "Optimized for retrieval" },
		];

		for (const m of ollamaModels) {
			console.log(`  ${c.cyan}${m.id}${c.reset}`);
			console.log(`     ${m.desc} | ${m.dim}d | ${m.size}`);
		}

		console.log(`\n${c.bold}Install:${c.reset} ollama pull nomic-embed-text`);
		console.log(`${c.bold}Current provider:${c.reset} ${currentProvider}`);
		if (config.ollamaEndpoint) {
			console.log(`${c.bold}Endpoint:${c.reset} ${config.ollamaEndpoint}`);
		}
		console.log("");
		return;
	}

	// Show current provider info
	console.log(`\n${c.dim}Current provider: ${currentProvider}${c.reset}`);
	console.log("ğŸ“¦ Fetching embedding models from OpenRouter...\n");

	const allModels = await discoverEmbeddingModels(forceRefresh);

	// Categorize models
	const freeModels = allModels.filter((m) => m.isFree);
	const paidModels = allModels.filter((m) => !m.isFree);
	const recommendedIds = new Set(RECOMMENDED_MODELS.map((m) => m.id));

	// Helper to print a model row
	const printModel = (model: typeof allModels[0], prefix = "  ") => {
		const id = model.id.length > 35 ? model.id.slice(0, 32) + "..." : model.id;
		const price = model.isFree ? `${c.green}FREE${c.reset}` : `$${model.pricePerMillion.toFixed(3)}/1M`;
		const context = `${Math.round(model.contextLength / 1000)}K`;
		const dim = model.dimension ? `${model.dimension}d` : "N/A";
		console.log(
			`${prefix}${id.padEnd(36)} ${model.provider.padEnd(10)} ${price.padEnd(20)} ${context.padEnd(6)} ${dim}`,
		);
	};

	// Print header
	const printHeader = () => {
		console.log(`  ${"Model".padEnd(36)} ${"Provider".padEnd(10)} ${"Price".padEnd(12)} ${"Context".padEnd(6)} Dim`);
		console.log("  " + "â”€".repeat(78));
	};

	if (freeOnly) {
		// Show only free models
		console.log(`${c.yellow}${c.bold}FREE EMBEDDING MODELS${c.reset}\n`);
		printHeader();

		if (freeModels.length === 0) {
			console.log(`  ${c.dim}No free models currently available${c.reset}`);
		} else {
			for (const model of freeModels) {
				printModel(model);
			}
		}
		console.log("");
		console.log(`${c.dim}Note: Free model availability changes frequently.${c.reset}`);
		console.log(`${c.dim}Use --refresh to fetch the latest list.${c.reset}\n`);
		return;
	}

	// Show all categories

	// 1. Curated Picks (4 categories)
	console.log(`${c.orange}${c.bold}â­ CURATED PICKS${c.reset}\n`);

	const picks = [
		{ label: "Best Quality", emoji: "ğŸ†", model: CURATED_PICKS.bestQuality, desc: "Top-tier code understanding" },
		{ label: "Best Balanced", emoji: "âš–ï¸", model: CURATED_PICKS.bestBalanced, desc: "Excellent quality/price ratio" },
		{ label: "Best Value", emoji: "ğŸ’°", model: CURATED_PICKS.bestValue, desc: "Great quality, lowest cost" },
		{ label: "Fastest", emoji: "âš¡", model: CURATED_PICKS.fastest, desc: "Optimized for speed" },
	];

	for (const pick of picks) {
		const price = pick.model.isFree ? `${c.green}FREE${c.reset}` : `$${pick.model.pricePerMillion.toFixed(3)}/1M`;
		const context = `${Math.round(pick.model.contextLength / 1000)}K`;
		const dim = pick.model.dimension ? `${pick.model.dimension}d` : "";
		console.log(`  ${pick.emoji} ${c.bold}${pick.label}${c.reset}: ${c.cyan}${pick.model.id}${c.reset}`);
		console.log(`     ${pick.desc} | ${price} | ${context} ctx | ${dim}`);
	}
	console.log("");

	// 3. Free Models (if any)
	if (freeModels.length > 0) {
		console.log(`${c.green}${c.bold}ğŸ†“ FREE MODELS${c.reset} ${c.dim}(Currently available)${c.reset}\n`);
		printHeader();
		for (const model of freeModels.slice(0, 10)) {
			printModel(model);
		}
		if (freeModels.length > 10) {
			console.log(`  ${c.dim}... and ${freeModels.length - 10} more free models${c.reset}`);
		}
		console.log("");
	}

	// 4. Other Paid Models
	const otherPaid = paidModels.filter((m) => !recommendedIds.has(m.id));
	if (otherPaid.length > 0) {
		console.log(`${c.cyan}${c.bold}ğŸ’° OTHER PAID MODELS${c.reset}\n`);
		printHeader();
		for (const model of otherPaid) {
			printModel(model);
		}
		console.log("");
	}

	// Summary
	console.log(`${c.bold}Summary:${c.reset} ${allModels.length} total models (${freeModels.length} free, ${paidModels.length} paid)`);
	console.log(`\n${c.dim}Use --free to show only free models, --refresh to update from API${c.reset}\n`);
}

// ============================================================================
// Helper Functions
// ============================================================================

async function promptForApiKey(): Promise<void> {
	console.log("OpenRouter API key required for embeddings.");
	console.log("Get yours at: https://openrouter.ai/keys\n");

	const apiKey = await input({
		message: "Enter your OpenRouter API key:",
		validate: (value) => {
			if (!value.trim()) {
				return "API key is required";
			}
			if (!value.startsWith("sk-or-")) {
				return "Invalid format. OpenRouter keys start with 'sk-or-'";
			}
			return true;
		},
	});

	saveGlobalConfig({ openrouterApiKey: apiKey });
	console.log("\nâœ… API key saved.");
}

// ============================================================================
// Benchmark Command
// ============================================================================

/** Directories to always exclude when discovering files */
const EXCLUDE_DIRS = new Set([
	"node_modules", ".git", ".svn", ".hg", "dist", "build", "out",
	".next", ".nuxt", ".output", "coverage", ".cache", ".claudemem",
	"__pycache__", ".pytest_cache", "venv", ".venv", "target",
]);

// Note: createBenchmarkProgress is imported from ./ui/index.js

interface BenchmarkResult {
	model: string;
	speedMs: number;
	cost: number | undefined;
	dimension: number;
	contextLength: number;
	chunks: number;
	// Quality metrics
	ndcg: number;
	mrr: number;
	hitRate: { k1: number; k3: number; k5: number };
	error?: string;
}

/**
 * Discover source files and parse them into chunks for benchmarking
 */
async function discoverAndChunkFiles(projectPath: string, maxChunks: number): Promise<string[]> {
	const files: string[] = [];

	// Walk directory to find source files
	const walk = (dir: string) => {
		try {
			const entries = readdirSync(dir, { withFileTypes: true });
			for (const entry of entries) {
				const fullPath = join(dir, entry.name);

				if (entry.isDirectory()) {
					// Skip excluded directories
					if (!EXCLUDE_DIRS.has(entry.name) && !entry.name.startsWith(".")) {
						walk(fullPath);
					}
				} else if (entry.isFile()) {
					// Check if file can be chunked (supported language)
					if (canChunkFile(fullPath)) {
						files.push(fullPath);
					}
				}
			}
		} catch {
			// Ignore permission errors
		}
	};

	walk(projectPath);

	// Parse files into chunks
	const allChunks: string[] = [];
	for (const filePath of files) {
		if (allChunks.length >= maxChunks) break;

		try {
			const content = readFileSync(filePath, "utf-8");
			const fileHash = createHash("md5").update(content).digest("hex");
			const chunks = await chunkFileByPath(content, filePath, fileHash);

			for (const chunk of chunks) {
				if (allChunks.length >= maxChunks) break;
				allChunks.push(chunk.content);
			}
		} catch {
			// Skip files that can't be read/parsed
		}
	}

	return allChunks;
}

/**
 * Discover source files and parse them into chunks WITH file paths
 * (needed for auto test query generation)
 */
async function discoverAndChunkFilesWithPaths(
	projectPath: string,
	maxChunks: number,
): Promise<Array<{ content: string; fileName: string }>> {
	const files: string[] = [];

	// Walk directory to find source files
	const walk = (dir: string) => {
		try {
			const entries = readdirSync(dir, { withFileTypes: true });
			for (const entry of entries) {
				const fullPath = join(dir, entry.name);

				if (entry.isDirectory()) {
					if (!EXCLUDE_DIRS.has(entry.name) && !entry.name.startsWith(".")) {
						walk(fullPath);
					}
				} else if (entry.isFile()) {
					if (canChunkFile(fullPath)) {
						files.push(fullPath);
					}
				}
			}
		} catch {
			// Ignore permission errors
		}
	};

	walk(projectPath);

	// Sort files for reproducible chunk selection
	files.sort();

	// Parse files into chunks with file paths
	const allChunks: Array<{ content: string; fileName: string }> = [];
	for (const filePath of files) {
		if (allChunks.length >= maxChunks) break;

		try {
			const content = readFileSync(filePath, "utf-8");
			const fileHash = createHash("md5").update(content).digest("hex");
			const chunks = await chunkFileByPath(content, filePath, fileHash);
			const fileName = filePath.split("/").pop() || "";

			for (const chunk of chunks) {
				if (allChunks.length >= maxChunks) break;
				allChunks.push({ content: chunk.content, fileName });
			}
		} catch {
			// Skip files that can't be read/parsed
		}
	}

	return allChunks;
}

async function handleBenchmark(args: string[]): Promise<void> {
	if (!noLogo) printLogo();

	const c = {
		reset: "\x1b[0m",
		bold: "\x1b[1m",
		dim: "\x1b[2m",
		cyan: "\x1b[36m",
		green: "\x1b[38;5;78m",
		yellow: "\x1b[33m",
		red: "\x1b[31m",
		orange: "\x1b[38;5;209m",
	};

	// Check for API key
	if (!hasApiKey()) {
		console.error("Error: OpenRouter API key not configured.");
		console.error("Run 'claudemem init' to set up, or set OPENROUTER_API_KEY.");
		process.exit(1);
	}

	// Parse flags
	const useRealData = args.includes("--real");
	const verbose = args.includes("--verbose") || args.includes("-v");
	const autoMode = args.includes("--auto");

	// Parse --models flag (support multiple formats)
	let models: string[];
	const modelsArgEquals = args.find((a) => a.startsWith("--models="));
	const modelsArgNoEquals = args.find((a) => a.startsWith("--models") && a.length > 8 && !a.includes("="));
	const modelsArgIndex = args.findIndex((a) => a === "--models");

	if (modelsArgEquals) {
		// --models=model1,model2
		models = modelsArgEquals.replace("--models=", "").split(",").map((s) => s.trim());
	} else if (modelsArgNoEquals) {
		// --modelsmodel1,model2 (typo - missing =)
		models = modelsArgNoEquals.replace("--models", "").split(",").map((s) => s.trim());
		console.log(`${c.dim}(Note: use --models= for clarity)${c.reset}`);
	} else if (modelsArgIndex !== -1 && args[modelsArgIndex + 1] && !args[modelsArgIndex + 1].startsWith("-")) {
		// --models model1,model2 (space-separated)
		models = args[modelsArgIndex + 1].split(",").map((s) => s.trim());
	} else {
		// Default models
		models = [
			CURATED_PICKS.bestBalanced.id,  // qwen/qwen3-embedding-8b
			"openai/text-embedding-3-small",
		];
	}

	const projectPath = process.cwd();

	console.log(`\n${c.orange}${c.bold}ğŸ EMBEDDING MODEL BENCHMARK${c.reset}\n`);

	// Get chunks with file paths (always needed for quality testing)
	console.log(`${c.dim}Parsing source files...${c.reset}`);
	const chunksWithPaths = await discoverAndChunkFilesWithPaths(projectPath, useRealData ? 100 : 50);
	if (chunksWithPaths.length === 0) {
		console.error("No source files found in the current directory.");
		process.exit(1);
	}

	// Get test queries - either auto-generated or predefined
	let testQueries: TestQuery[];
	if (autoMode) {
		testQueries = await extractAutoTestQueries(projectPath);
		if (testQueries.length === 0) {
			console.error("No functions with docstrings found. Run without --auto to use predefined queries.");
			process.exit(1);
		}
	} else {
		// Predefined queries for claudemem codebase
		testQueries = [
			{ query: "convert text to vector representation", category: "semantic", expected: [{ file: "embeddings.ts", relevance: 3 }, { file: "store.ts", relevance: 2 }], description: "embedding" },
			{ query: "split code into smaller pieces", category: "semantic", expected: [{ file: "chunker.ts", relevance: 3 }, { file: "parser-manager.ts", relevance: 2 }], description: "chunking" },
			{ query: "find similar code based on meaning", category: "semantic", expected: [{ file: "store.ts", relevance: 3 }, { file: "indexer.ts", relevance: 2 }], description: "search" },
			{ query: "LanceDB vector database", category: "keyword", expected: [{ file: "store.ts", relevance: 3 }], description: "LanceDB" },
			{ query: "tree-sitter parser AST", category: "keyword", expected: [{ file: "parser-manager.ts", relevance: 3 }, { file: "chunker.ts", relevance: 2 }], description: "tree-sitter" },
			{ query: "OpenRouter API embeddings", category: "keyword", expected: [{ file: "embeddings.ts", relevance: 3 }, { file: "config.ts", relevance: 2 }], description: "OpenRouter" },
			{ query: "how do I search for code", category: "natural", expected: [{ file: "indexer.ts", relevance: 3 }, { file: "store.ts", relevance: 2 }], description: "search usage" },
			{ query: "createEmbeddingsClient function", category: "api", expected: [{ file: "embeddings.ts", relevance: 3 }], description: "embeddings API" },
			{ query: "VectorStore search method", category: "api", expected: [{ file: "store.ts", relevance: 3 }], description: "vector store" },
			{ query: "handle API timeout retry", category: "error", expected: [{ file: "embeddings.ts", relevance: 3 }], description: "retry logic" },
		];
	}

	console.log(`${c.dim}Testing ${models.length} models with ${chunksWithPaths.length} chunks + ${testQueries.length} quality queries${c.reset}\n`);

	// Create multi-line progress display
	const progress = createBenchmarkProgress(models);
	progress.start();

	// Benchmark directory for temp stores
	const benchDbBase = join(projectPath, ".claudemem", "benchmark");
	if (!existsSync(benchDbBase)) {
		mkdirSync(benchDbBase, { recursive: true });
	}

	// Separate local (Ollama) and cloud models
	const ollamaModels = models.filter((m) => m.startsWith("ollama/"));
	const cloudModels = models.filter((m) => !m.startsWith("ollama/"));

	// Helper to benchmark a single model
	const benchmarkModel = async (modelId: string): Promise<BenchmarkResult> => {
		const startTime = Date.now();
		const modelSlug = modelId.replace(/[^a-zA-Z0-9]/g, "-");
		const tempDbPath = join(benchDbBase, modelSlug);

		try {
			const client = createEmbeddingsClient({ model: modelId });

			// Truncate chunks to fit model's context window
			const chunkTexts = truncateForModel(
				chunksWithPaths.map((c) => c.content),
				modelId,
			);

			// Phase 1: Embed all chunks
			const embedResult = await client.embed(
				chunkTexts,
				(completed, total, inProgress) => {
					progress.update(modelId, completed, total, inProgress ?? 0, "embed");
				},
			);

			const embedTimeMs = Date.now() - startTime;

			// Phase 2: Build temp vector store and run quality queries
			progress.update(modelId, 0, testQueries.length, testQueries.length, "quality");

			// Clear existing temp db
			if (existsSync(tempDbPath)) {
				const { rmSync } = await import("node:fs");
				rmSync(tempDbPath, { recursive: true, force: true });
			}

			const { createVectorStore } = await import("./core/store.js");
			const store = createVectorStore(tempDbPath);
			await store.initialize();

			// Add chunks with embeddings (filter out failed ones with empty vectors)
			const chunksForStore = chunksWithPaths
				.map((chunk, i) => ({
					id: `chunk-${i}`,
					contentHash: "", // Not used in benchmarking
					content: chunk.content,
					filePath: chunk.fileName,
					startLine: 0,
					endLine: 0,
					language: "unknown",
					chunkType: "block" as const,
					fileHash: `hash-${i}`,
					vector: embedResult.embeddings[i],
				}))
				.filter((chunk) => chunk.vector && chunk.vector.length > 0);

			if (chunksForStore.length === 0) {
				throw new Error("All chunks failed to embed");
			}
			await store.addChunks(chunksForStore);

			// Run quality queries
			let mrrSum = 0;
			let ndcgSum = 0;
			const hitCounts = { k1: 0, k3: 0, k5: 0 };

			for (let qi = 0; qi < testQueries.length; qi++) {
				const tq = testQueries[qi];
				progress.update(modelId, qi, testQueries.length, 1, "quality");

				// Embed query and search
				const queryVector = await client.embedOne(tq.query);
				const searchResults = await store.search(tq.query, queryVector, { limit: 5 });

				// Build relevance map
				const relevanceMap = new Map<string, number>();
				for (const exp of tq.expected) {
					relevanceMap.set(exp.file, exp.relevance);
				}

				// Score results
				let firstRelevantRank: number | null = null;
				const actualRelevances: number[] = [];
				const idealRelevances = tq.expected.map((e) => e.relevance);

				for (let i = 0; i < Math.min(searchResults.length, 5); i++) {
					const fileName = searchResults[i].chunk.filePath;
					let relevance = 0;
					for (const [expFile, expRel] of relevanceMap) {
						if (fileName.includes(expFile)) {
							relevance = expRel;
							break;
						}
					}
					actualRelevances.push(relevance);
					if (relevance > 0 && firstRelevantRank === null) {
						firstRelevantRank = i + 1;
					}
				}

				// Pad to 5
				while (actualRelevances.length < 5) actualRelevances.push(0);

				// Calculate NDCG
				const dcg = calculateDCG(actualRelevances);
				const idcg = calculateDCG([...idealRelevances].sort((a, b) => b - a));
				const ndcg = idcg === 0 ? 0 : dcg / idcg;

				ndcgSum += ndcg;
				if (firstRelevantRank !== null) {
					mrrSum += 1 / firstRelevantRank;
					if (firstRelevantRank <= 1) hitCounts.k1++;
					if (firstRelevantRank <= 3) hitCounts.k3++;
					if (firstRelevantRank <= 5) hitCounts.k5++;
				}
			}

			// Cleanup
			await store.close();

			const n = testQueries.length;
			progress.finish(modelId);

			// Find first non-empty embedding for dimension
			const firstValidEmbedding = embedResult.embeddings.find((e) => e && e.length > 0);

			return {
				model: modelId,
				speedMs: embedTimeMs,
				cost: embedResult.cost,
				dimension: firstValidEmbedding?.length || 0,
				contextLength: getModelContextLength(modelId),
				chunks: chunksWithPaths.length,
				ndcg: (ndcgSum / n) * 100,
				mrr: (mrrSum / n) * 100,
				hitRate: {
					k1: (hitCounts.k1 / n) * 100,
					k3: (hitCounts.k3 / n) * 100,
					k5: (hitCounts.k5 / n) * 100,
				},
			};
		} catch (error) {
			const errMsg = error instanceof Error ? error.message : String(error);
			progress.setError(modelId, errMsg);
			return {
				model: modelId,
				speedMs: Date.now() - startTime,
				cost: undefined,
				dimension: 0,
				contextLength: getModelContextLength(modelId),
				chunks: 0,
				ndcg: 0,
				mrr: 0,
				hitRate: { k1: 0, k3: 0, k5: 0 },
				error: errMsg,
			};
		}
	};

	// Run cloud models in PARALLEL (they use different APIs)
	const cloudPromises = cloudModels.map((modelId) => benchmarkModel(modelId));
	const cloudResults = await Promise.all(cloudPromises);

	// Run Ollama models SEQUENTIALLY (they share local GPU/CPU)
	const ollamaResults: BenchmarkResult[] = [];
	for (const modelId of ollamaModels) {
		const result = await benchmarkModel(modelId);
		ollamaResults.push(result);
	}

	const results = [...cloudResults, ...ollamaResults];
	progress.stop();

	// Sort by NDCG (quality first)
	results.sort((a, b) => (a.error ? 1 : 0) - (b.error ? 1 : 0) || b.ndcg - a.ndcg);

	// Display results table
	console.log(`\n${c.bold}Results (sorted by quality):${c.reset}\n`);
	console.log(`  ${"Model".padEnd(28)} ${"Speed".padEnd(7)} ${"Cost".padEnd(11)} ${"Ctx".padEnd(6)} ${"Dim".padEnd(6)} ${"NDCG".padEnd(6)} ${"MRR".padEnd(6)} ${"Hit@5"}`);
	console.log("  " + "â”€".repeat(82));

	// Truncate long model names
	const truncate = (s: string, max = 26) => s.length > max ? s.slice(0, max - 1) + "â€¦" : s;

	// Format context length (e.g., 32000 -> "32K")
	const fmtCtx = (ctx: number) => ctx >= 1000 ? `${Math.round(ctx / 1000)}K` : String(ctx);

	// Calculate best/worst for highlighting
	const successResults = results.filter((r) => !r.error);
	const minSpeed = Math.min(...successResults.map((r) => r.speedMs));
	const maxSpeed = Math.max(...successResults.map((r) => r.speedMs));
	const costsWithValues = successResults.filter((r) => r.cost !== undefined);
	const minCost = costsWithValues.length > 0 ? Math.min(...costsWithValues.map((r) => r.cost!)) : undefined;
	const maxCost = costsWithValues.length > 0 ? Math.max(...costsWithValues.map((r) => r.cost!)) : undefined;
	const maxNdcg = Math.max(...successResults.map((r) => r.ndcg));
	const minNdcg = Math.min(...successResults.map((r) => r.ndcg));
	const shouldHighlight = successResults.length > 1;

	for (const r of results) {
		const displayName = truncate(r.model).padEnd(28);
		if (r.error) {
			console.log(`  ${c.red}${displayName} ERROR${c.reset}`);
			console.log(`    ${c.dim}${r.error}${c.reset}`);
			continue;
		}

		// Speed with highlighting
		const speedVal = `${(r.speedMs / 1000).toFixed(1)}s`;
		let speed = speedVal.padEnd(7);
		if (shouldHighlight && r.speedMs === minSpeed) {
			speed = `${c.green}${speedVal.padEnd(7)}${c.reset}`;
		} else if (shouldHighlight && r.speedMs === maxSpeed && minSpeed !== maxSpeed) {
			speed = `${c.red}${speedVal.padEnd(7)}${c.reset}`;
		}

		// Cost with highlighting (FREE for local/ollama models)
		const isLocal = r.model.startsWith("ollama/");
		const costVal = isLocal ? "FREE" : (r.cost !== undefined ? `$${r.cost.toFixed(5)}` : "N/A");
		let cost = costVal.padEnd(11);
		if (isLocal) {
			cost = `${c.green}${costVal.padEnd(11)}${c.reset}`;
		} else if (shouldHighlight && r.cost !== undefined && minCost !== undefined && r.cost === minCost) {
			cost = `${c.green}${costVal.padEnd(11)}${c.reset}`;
		} else if (shouldHighlight && r.cost !== undefined && maxCost !== undefined && r.cost === maxCost && minCost !== maxCost) {
			cost = `${c.red}${costVal.padEnd(11)}${c.reset}`;
		}

		// Context length
		const ctx = fmtCtx(r.contextLength).padEnd(6);

		// NDCG with highlighting
		const ndcgVal = `${r.ndcg.toFixed(0)}%`;
		let ndcg = ndcgVal.padEnd(6);
		if (shouldHighlight && r.ndcg === maxNdcg) {
			ndcg = `${c.green}${ndcgVal.padEnd(6)}${c.reset}`;
		} else if (shouldHighlight && r.ndcg === minNdcg && minNdcg !== maxNdcg) {
			ndcg = `${c.red}${ndcgVal.padEnd(6)}${c.reset}`;
		}

		const dim = `${r.dimension}d`.padEnd(6);
		const mrr = `${r.mrr.toFixed(0)}%`.padEnd(6);
		const hit5 = `${r.hitRate.k5.toFixed(0)}%`;

		console.log(`  ${displayName} ${speed} ${cost} ${ctx} ${dim} ${ndcg} ${mrr} ${hit5}`);
	}

	// Summary
	if (successResults.length > 0) {
		const fastest = successResults.reduce((a, b) => a.speedMs < b.speedMs ? a : b);
		const cheapest = costsWithValues.length > 0 ? costsWithValues.reduce((a, b) => (a.cost || Infinity) < (b.cost || Infinity) ? a : b) : null;
		const bestQuality = successResults.reduce((a, b) => a.ndcg > b.ndcg ? a : b);

		console.log(`\n${c.bold}Summary:${c.reset}`);
		console.log(`  ${c.green}ğŸ† Best Quality:${c.reset} ${bestQuality.model} (NDCG: ${bestQuality.ndcg.toFixed(0)}%)`);
		console.log(`  ${c.green}âš¡ Fastest:${c.reset} ${fastest.model} (${(fastest.speedMs / 1000).toFixed(2)}s)`);
		if (cheapest) {
			console.log(`  ${c.green}ğŸ’° Cheapest:${c.reset} ${cheapest.model} ($${cheapest.cost?.toFixed(6)})`);
		}
	}

	console.log(`\n${c.dim}Metrics: NDCG (quality), MRR (rank), Hit@5 (found in top 5)${c.reset}`);
	console.log(`${c.dim}Use --auto to generate queries from docstrings (works on any codebase)${c.reset}`);
	console.log(`${c.dim}Use --verbose for detailed per-query results${c.reset}\n`);
}

// ============================================================================
// LLM Benchmark Handler
// ============================================================================

async function handleBenchmarkLLM(args: string[]): Promise<void> {
	if (!noLogo) printLogo();

	const c = {
		reset: "\x1b[0m",
		bold: "\x1b[1m",
		dim: "\x1b[2m",
		cyan: "\x1b[36m",
		green: "\x1b[38;5;78m",
		yellow: "\x1b[33m",
		red: "\x1b[31m",
		orange: "\x1b[38;5;209m",
	};

	// Parse flags
	const getFlag = (name: string): string | undefined => {
		const idx = args.findIndex((a) => a.startsWith(`--${name}=`));
		if (idx !== -1) return args[idx].split("=")[1];
		const idxSpace = args.findIndex((a) => a === `--${name}`);
		if (idxSpace !== -1 && args[idxSpace + 1] && !args[idxSpace + 1].startsWith("-")) {
			return args[idxSpace + 1];
		}
		return undefined;
	};

	const generatorsStr = getFlag("generators") || "anthropic";
	const judgesStr = getFlag("judges");
	const casesStr = getFlag("cases") || "10";
	const testCaseCount = casesStr.toLowerCase() === "all" ? Infinity : parseInt(casesStr, 10);
	const outputFormat = getFlag("format") || "cli";
	const verbose = args.includes("--verbose") || args.includes("-v");

	// Parse generator specs - import DEFAULT_LLM_MODELS for resolving defaults
	const { parseGeneratorSpec } = await import("./benchmark/generators/index.js");
	const { DEFAULT_LLM_MODELS } = await import("./llm/client.js");
	const generatorSpecs = generatorsStr.split(",").map((s) => s.trim());
	const generatorConfigs = generatorSpecs.map((spec) => {
		const parsed = parseGeneratorSpec(spec);
		// Resolve model from defaults if not specified
		const resolvedModel = parsed.model || DEFAULT_LLM_MODELS[parsed.provider];
		return {
			provider: parsed.provider,
			model: resolvedModel,
			displayName: spec === parsed.provider ? `${spec} (${resolvedModel})` : spec,
			endpoint: parsed.endpoint, // For local providers (lmstudio uses port 1234, ollama uses 11434)
		};
	});

	// Parse judge specs
	const judgeModels = judgesStr ? judgesStr.split(",").map((s) => s.trim()) : [];

	console.log(`\n${c.orange}${c.bold}ğŸ LLM BENCHMARK${c.reset}\n`);
	console.log(`${c.dim}Generators: ${generatorSpecs.join(", ")}${c.reset}`);
	console.log(`${c.dim}Judges: ${judgeModels.length > 0 ? judgeModels.join(", ") : "none (AST only)"}${c.reset}`);
	console.log(`${c.dim}Test cases: ${testCaseCount === Infinity ? "all" : testCaseCount}${c.reset}\n`);

	// Import benchmark module
	const { runBenchmark, createReporter } = await import("./benchmark/index.js");

	// Types (inline to avoid compile-time dependency on dynamic import)
	type BenchmarkPhase = "preparing" | "generating" | "judging" | "scoring" | "reporting";
	type ReportFormat = "cli" | "json" | "detailed";
	type TestCaseType = "file_summary" | "symbol_summary";
	type LLMProvider = "claude-code" | "anthropic" | "anthropic-batch" | "openrouter" | "local";
	type BenchmarkConfig = {
		generators: Array<{ provider: LLMProvider; model: string; displayName: string }>;
		judges: string[];
		testCaseCount: number;
		testCaseTypes: TestCaseType[];
		projectPath: string;
		outputFormats: ReportFormat[];
		onProgress?: (phase: BenchmarkPhase, completed: number, total: number, details?: string) => void;
		verbose?: boolean;
	};

	// Create multi-model progress renderer (each model gets its own row)
	const createLLMMultiProgress = (generatorNames: string[], judgeNames: string[] = []) => {
		const globalStartTime = Date.now();
		const ANIM = ["â–“", "â–’", "â–‘", "â–’"];
		let animFrame = 0;
		let interval: ReturnType<typeof setInterval> | null = null;
		const hasJudges = judgeNames.length > 0;
		// +1 for summary line, +1 for separator if judges exist
		const totalLines = generatorNames.length + judgeNames.length + 1 + (hasJudges ? 1 : 0);
		let renderCount = 0; // Track render calls for debugging

		// State per generator
		const generatorState = new Map<string, {
			completed: number;
			total: number;
			phase: string;
			done: boolean;
			started: boolean;
			error?: string;
			startTime: number;
			endTime?: number;
		}>();
		for (const name of generatorNames) {
			generatorState.set(name, {
				completed: 0,
				total: 0,
				phase: "waiting",
				done: false,
				started: false,
				startTime: globalStartTime,
			});
		}

		// State per judge
		const judgeState = new Map<string, {
			completed: number;
			total: number;
			phase: string;
			done: boolean;
			started: boolean;
			error?: string;
			startTime: number;
			endTime?: number;
		}>();
		for (const name of judgeNames) {
			judgeState.set(name, {
				completed: 0,
				total: 0,
				phase: "waiting",
				done: false,
				started: false,
				startTime: globalStartTime,
			});
		}

		// Global phase tracking
		let globalPhase = "preparing";

		const formatTime = (ms: number) => {
			const s = Math.floor(ms / 1000);
			const m = Math.floor(s / 60);
			return m > 0 ? `${m.toString().padStart(2, "0")}:${(s % 60).toString().padStart(2, "0")}` : `00:${s.toString().padStart(2, "0")}`;
		};

		// Helper to extract a friendly display name from full generator/judge name
		// Handles formats:
		//   "provider (model)" -> "model-family/provider" e.g. "anthropic (claude-sonnet-4-5)" -> "sonnet"
		//   "batch/sonnet" -> "sonnet/batch"
		//   "Model Name (Provider)" -> "model/provider" e.g. "Claude Sonnet 4.5 (Anthropic)" -> "sonnet"
		const extractDisplayName = (name: string): string => {
			// Try to extract from format: "something (something-else)"
			const fullMatch = name.match(/^(.+?)\s*\((.+?)\)$/);
			if (fullMatch) {
				const beforeParen = fullMatch[1].trim();
				const inParen = fullMatch[2].trim();

				// Determine which is model and which is provider
				// If inParen contains "claude-" it's the model, otherwise it's the provider
				let modelPart: string;
				let providerPart: string;

				if (inParen.includes("claude") || inParen.includes("-")) {
					// Format: "provider (model)" e.g. "anthropic (claude-sonnet-4-5)"
					providerPart = beforeParen.toLowerCase();
					modelPart = inParen;
				} else {
					// Format: "model (Provider)" e.g. "Claude Sonnet 4.5 (Anthropic)"
					modelPart = beforeParen;
					providerPart = inParen.toLowerCase();
				}

				// Extract model family: claude-sonnet-4-5 -> sonnet, Claude Sonnet 4.5 -> sonnet
				let modelFamily: string;
				const familyMatch = modelPart.match(/(?:claude[_-\s]*)?(opus|sonnet|haiku)/i);
				if (familyMatch) {
					modelFamily = familyMatch[1].toLowerCase();
				} else {
					// For other models, use last significant part
					const parts = modelPart.split(/[-/\s]/);
					modelFamily = parts.pop()?.toLowerCase() || modelPart.toLowerCase();
				}

				// Short provider names for disambiguation
				const shortProvider = providerPart === "anthropic" ? "" :
					providerPart === "batch" ? "/batch" :
					providerPart === "openrouter" || providerPart === "or" ? "/or" :
					providerPart === "local" ? "/local" :
					providerPart === "claude code" || providerPart === "cc" ? "/cc" :
					`/${providerPart.slice(0, 5)}`;

				return modelFamily + shortProvider;
			}

			// For batch/sonnet or provider/model style
			if (name.includes("/")) {
				const parts = name.split("/");
				const provider = parts[0].toLowerCase();
				const modelOrAlias = parts.slice(1).join("/");

				// Check for model family in the model part
				const familyMatch = modelOrAlias.match(/(opus|sonnet|haiku)/i);
				if (familyMatch) {
					const modelFamily = familyMatch[1].toLowerCase();
					// Add provider suffix if not anthropic
					const shortProvider = provider === "anthropic" ? "" :
						provider === "batch" ? "/batch" :
						provider === "openrouter" || provider === "or" ? "/or" :
						provider === "local" || provider === "lmstudio" || provider === "ollama" ? "/local" :
						`/${provider.slice(0, 5)}`;
					return modelFamily + shortProvider;
				}
				// Return as-is for non-claude models
				return modelOrAlias.length > 20 ? modelOrAlias.slice(0, 20) : modelOrAlias;
			}
			return name;
		};

		// Helper to render a single row
		const renderRow = (
			name: string,
			state: { completed: number; total: number; phase: string; done: boolean; started: boolean; error?: string; startTime: number; endTime?: number },
			icon: string = "â±"
		) => {
			const { completed, total, phase, done, started, error, startTime, endTime } = state;
			const elapsedMs = started ? (endTime || Date.now()) - startTime : 0;
			const elapsed = formatTime(elapsedMs);

			// Get friendly display name
			let displayName = extractDisplayName(name);
			if (displayName.length > 30) {
				displayName = displayName.slice(0, 27) + "...";
			}

			const width = 20;
			let bar: string;
			let percent: number;
			let status: string;

			if (error) {
				bar = `${c.red}${"âœ—".repeat(width)}${c.reset}`;
				percent = 0;
				status = `${c.red}âœ— error${c.reset}`;
			} else if (done) {
				bar = `${c.green}${"â–ˆ".repeat(width)}${c.reset}`;
				percent = 100;
				status = `${c.green}âœ“ done${c.reset}`;
			} else if (!started) {
				bar = `${c.dim}${"â–‘".repeat(width)}${c.reset}`;
				percent = 0;
				status = `${c.dim}â³ waiting${c.reset}`;
			} else {
				percent = total > 0 ? Math.round((completed / total) * 100) : 0;
				const filledWidth = Math.round((completed / Math.max(total, 1)) * width);
				const inProgressWidth = Math.min(1, width - filledWidth);
				const emptyWidth = Math.max(0, width - filledWidth - inProgressWidth);

				const filled = "â–ˆ".repeat(filledWidth);
				const animated = ANIM[animFrame];
				const empty = "â–‘".repeat(emptyWidth);
				bar = filled + animated + empty;
				// Show progress count for both generators and judges (per-test-case progress)
				status = `${phase}: ${completed}/${total}`;
			}

			process.stdout.write(`\r${icon} ${elapsed} â”‚ ${bar} ${percent.toString().padStart(3)}% â”‚ ${displayName.padEnd(30)} â”‚ ${status.padEnd(25)}\x1b[K\n`);
		};

		const render = () => {
			animFrame = (animFrame + 1) % ANIM.length;

			// Move cursor up to overwrite previous lines (more portable than save/restore)
			// Clear each line as we go up to ensure clean overwrites
			for (let i = 0; i < totalLines; i++) {
				process.stdout.write("\x1b[1A\x1b[2K");
			}

			// Render generator rows
			for (const name of generatorNames) {
				const state = generatorState.get(name)!;
				renderRow(name, state, "â±");
			}

			// Render separator and judge rows if judges exist
			if (hasJudges) {
				process.stdout.write(`\r${c.dim}${"â”€".repeat(90)}${c.reset}\x1b[K\n`);
				for (const name of judgeNames) {
					const state = judgeState.get(name)!;
					renderRow(name, state, "âš–");
				}
			}

			// Total line
			const totalElapsed = formatTime(Date.now() - globalStartTime);
			const genDoneCount = Array.from(generatorState.values()).filter(s => s.done).length;
			const judgeDoneCount = Array.from(judgeState.values()).filter(s => s.done).length;
			const statusParts = [`${genDoneCount}/${generatorNames.length} generators`];
			if (hasJudges) {
				statusParts.push(`${judgeDoneCount}/${judgeNames.length} judges`);
			}
			process.stdout.write(`\r${c.dim}â± ${totalElapsed} total â”‚ ${globalPhase} â”‚ ${statusParts.join(", ")}${c.reset}\x1b[K\n`);
		};

		return {
			start() {
				// Print initial state directly (no empty lines needed)
				// This avoids cursor positioning issues on first render
				for (const name of generatorNames) {
					const state = generatorState.get(name)!;
					renderRow(name, state, "â±");
				}
				if (hasJudges) {
					process.stdout.write(`\r${c.dim}${"â”€".repeat(90)}${c.reset}\x1b[K\n`);
					for (const name of judgeNames) {
						const state = judgeState.get(name)!;
						renderRow(name, state, "âš–");
					}
				}
				const totalElapsed = formatTime(0);
				process.stdout.write(`\r${c.dim}â± ${totalElapsed} total â”‚ preparing â”‚ 0/${generatorNames.length} generators${hasJudges ? `, 0/${judgeNames.length} judges` : ""}${c.reset}\x1b[K\n`);

				// Now start the interval for updates
				interval = setInterval(render, 100);
				if (interval.unref) interval.unref();
			},
			updateGenerator(name: string, completed: number, total: number, phase: string) {
				const state = generatorState.get(name);
				if (state) {
					if (!state.started) {
						state.started = true;
						state.startTime = Date.now();
					}
					state.completed = completed;
					state.total = total;
					state.phase = phase;
				}
			},
			finishGenerator(name: string) {
				const state = generatorState.get(name);
				if (state) {
					state.done = true;
					state.completed = state.total;
					state.endTime = Date.now();
				}
			},
			setGeneratorError(name: string, error: string) {
				const state = generatorState.get(name);
				if (state) {
					state.error = error;
					state.done = true;
					state.endTime = Date.now();
				}
			},
			updateJudge(name: string, completed: number, total: number, phase: string) {
				const state = judgeState.get(name);
				if (state) {
					if (!state.started) {
						state.started = true;
						state.startTime = Date.now();
					}
					state.completed = completed;
					state.total = total;
					state.phase = phase;
				}
			},
			finishJudge(name: string) {
				const state = judgeState.get(name);
				if (state) {
					state.done = true;
					state.completed = state.total;
					state.endTime = Date.now();
				}
			},
			setJudgeError(name: string, error: string) {
				const state = judgeState.get(name);
				if (state) {
					state.error = error;
					state.done = true;
					state.endTime = Date.now();
				}
			},
			setGlobalPhase(phase: string) {
				globalPhase = phase;
			},
			stop() {
				if (interval) {
					clearInterval(interval);
					interval = null;
				}
			},
			finish() {
				this.stop();
				// Final render - move cursor up and clear each line
				for (let i = 0; i < totalLines; i++) {
					process.stdout.write("\x1b[1A\x1b[2K");
				}

				// Helper to render final row
				const renderFinalRow = (name: string, state: typeof generatorState extends Map<string, infer V> ? V : never, icon: string) => {
					const elapsedMs = state.endTime ? state.endTime - state.startTime : Date.now() - state.startTime;
					const elapsed = formatTime(elapsedMs);

					let displayName = extractDisplayName(name);
					if (displayName.length > 30) {
						displayName = displayName.slice(0, 27) + "...";
					}

					if (state.error) {
						process.stdout.write(`\r${icon} ${elapsed} â”‚ ${c.red}${"âœ—".repeat(20)}${c.reset}   0% â”‚ ${displayName.padEnd(30)} â”‚ ${c.red}âœ— error${c.reset}\x1b[K\n`);
					} else {
						process.stdout.write(`\r${icon} ${elapsed} â”‚ ${c.green}${"â–ˆ".repeat(20)}${c.reset} 100% â”‚ ${displayName.padEnd(30)} â”‚ ${c.green}âœ“ done${c.reset}\x1b[K\n`);
					}
				};

				// Render generator rows
				for (const name of generatorNames) {
					const state = generatorState.get(name)!;
					renderFinalRow(name, state, "â±");
				}

				// Render separator and judge rows if judges exist
				if (hasJudges) {
					process.stdout.write(`\r${c.dim}${"â”€".repeat(90)}${c.reset}\x1b[K\n`);
					for (const name of judgeNames) {
						const state = judgeState.get(name)!;
						renderFinalRow(name, state, "âš–");
					}
				}

				const totalElapsed = formatTime(Date.now() - globalStartTime);
				process.stdout.write(`\r${c.green}âœ“${c.reset} ${c.bold}Completed in ${totalElapsed}${c.reset}\x1b[K\n\n`);
			},
		};
	};

	// Create multi-model progress display with generators and judges
	const generatorDisplayNames = generatorConfigs.map(g => g.displayName);
	const progress = createLLMMultiProgress(generatorDisplayNames, judgeModels);
	progress.start();

	// Map display names back to track progress
	const displayNameToConfig = new Map(generatorConfigs.map(g => [g.displayName, g]));

	const onProgress = (phase: BenchmarkPhase, completed: number, total: number, details?: string) => {
		progress.setGlobalPhase(phase);
		// Parse model name from details if present
		if (details) {
			// Check if this is a judge progress update (format: "Judge <judge>: <completed>/<total> for <generator>")
			const judgeMatch = details.match(/^Judge\s+(.+?):\s*(\d+)\/(\d+)/);
			if (judgeMatch) {
				const judgeName = judgeMatch[1].trim();
				const judgeCompleted = parseInt(judgeMatch[2], 10);
				const judgeTotal = parseInt(judgeMatch[3], 10);
				// Find matching judge
				for (const jm of judgeModels) {
					if (jm.includes(judgeName) || judgeName.includes(jm.split("/").pop() || jm)) {
						if (judgeCompleted >= judgeTotal) {
							progress.finishJudge(jm);
						} else {
							progress.updateJudge(jm, judgeCompleted, judgeTotal, "judging");
						}
						break;
					}
				}
				return;
			}

			// Check for generator progress
			const match = details.match(/(?:Running|Completed|Failed|Judging|Scoring)\s+(.+?)(?:\s*\(|\.\.\.|\s*$)/);
			if (match) {
				const modelName = match[1].trim();
				// Find matching display name
				for (const [displayName] of displayNameToConfig) {
					if (displayName.includes(modelName) || modelName.includes(displayName.split(" ")[0])) {
						if (details.includes("Failed")) {
							// Extract error message from details
							const errorMatch = details.match(/\((.+?)\)/);
							const errorMsg = errorMatch ? errorMatch[1] : "all tests failed";
							progress.setGeneratorError(displayName, errorMsg);
						} else if (details.includes("Completed")) {
							progress.finishGenerator(displayName);
						} else {
							progress.updateGenerator(displayName, completed, total, phase);
						}
						break;
					}
				}
			}
		}
	};

	// Run benchmark
	const config: BenchmarkConfig = {
		generators: generatorConfigs,
		judges: judgeModels,
		testCaseCount,
		testCaseTypes: ["file_summary", "symbol_summary"],
		projectPath: process.cwd(),
		outputFormats: [outputFormat as ReportFormat],
		onProgress,
		verbose,
	};

	try {
		// Suppress console.warn during benchmark to prevent progress display corruption
		const originalWarn = console.warn;
		console.warn = () => {};

		const { results, flushDiagnostics } = await runBenchmark(config);

		// Restore console.warn
		console.warn = originalWarn;

		// Finish progress display
		progress.finish();

		// Flush diagnostic messages now that progress display is stopped
		flushDiagnostics();

		// Generate report
		const reporter = createReporter(outputFormat as ReportFormat);
		const report = await reporter.report(results);
		console.log(report);

		// Save JSON if requested
		if (outputFormat === "json" || args.includes("--save")) {
			const { writeFileSync } = await import("node:fs");
			const { join } = await import("node:path");
			const outputPath = join(process.cwd(), ".claudemem", "llm-benchmark.json");
			const jsonReporter = createReporter("json");
			const jsonReport = await jsonReporter.report(results);
			writeFileSync(outputPath, jsonReport);
			console.log(`\n${c.dim}Results saved to ${outputPath}${c.reset}`);
		}
	} catch (error) {
		// Restore console.warn in case of error
		console.warn = console.warn || (() => {});
		progress.stop();
		console.error(`\n${c.red}Benchmark failed: ${error instanceof Error ? error.message : error}${c.reset}`);
		process.exit(1);
	}
}

// ============================================================================
// Quality Test Types
// ============================================================================

/**
 * Query categories for comprehensive evaluation
 */
type QueryCategory = "semantic" | "keyword" | "natural" | "error" | "api";

/**
 * Test query with graded relevance (0-3 scale like CodeSearchNet)
 * 0 = irrelevant, 1 = marginally relevant, 2 = relevant, 3 = highly relevant
 */
interface TestQuery {
	query: string;
	/** Category of query for analysis */
	category: QueryCategory;
	/** Expected results with graded relevance scores */
	expected: Array<{
		file: string;
		relevance: 0 | 1 | 2 | 3;
	}>;
	/** Description of what we're testing */
	description: string;
}

interface QueryResult {
	query: string;
	category: QueryCategory;
	/** Rank at which first relevant result was found (null if not found) */
	firstRelevantRank: number | null;
	/** Top 5 results with their relevance scores */
	results: Array<{
		file: string;
		relevance: number;
		rank: number;
	}>;
	/** DCG (Discounted Cumulative Gain) at K=5 */
	dcg: number;
	/** IDCG (Ideal DCG) - best possible DCG */
	idcg: number;
	/** NDCG = DCG / IDCG */
	ndcg: number;
}

interface TestResult {
	model: string;
	indexTimeMs: number;
	indexCost?: number;
	queryResults: QueryResult[];
	/** Metrics computed at different K values */
	metrics: {
		/** Hit Rate: % of queries with at least one relevant result in top K */
		hitRate: { k1: number; k3: number; k5: number };
		/** MRR: Mean Reciprocal Rank */
		mrr: number;
		/** Mean NDCG across all queries */
		ndcg: number;
		/** Precision: avg % of top K results that are relevant */
		precision: { k1: number; k3: number; k5: number };
	};
	/** Metrics broken down by category */
	byCategory: Record<QueryCategory, { count: number; mrr: number; ndcg: number }>;
	error?: string;
}

/**
 * Calculate DCG (Discounted Cumulative Gain)
 * DCG = Î£ (relevance_i / log2(i + 1))
 */
function calculateDCG(relevances: number[]): number {
	return relevances.reduce((sum, rel, i) => {
		return sum + rel / Math.log2(i + 2); // i+2 because rank starts at 1
	}, 0);
}

/**
 * Calculate NDCG (Normalized DCG)
 */
function calculateNDCG(actualRelevances: number[], idealRelevances: number[]): number {
	const dcg = calculateDCG(actualRelevances);
	const idcg = calculateDCG(idealRelevances.sort((a, b) => b - a));
	return idcg === 0 ? 0 : dcg / idcg;
}

/**
 * Extract test queries automatically from codebase docstrings
 * Uses docstrings as queries and their source file as expected result
 * This enables testing on ANY codebase, not just claudemem
 */
async function extractAutoTestQueries(projectPath: string): Promise<TestQuery[]> {
	const queries: TestQuery[] = [];
	const seenQueries = new Set<string>();

	// Discover and chunk files WITH file paths
	const chunksWithFiles = await discoverAndChunkFilesWithPaths(projectPath, 500);

	// Regex patterns for extracting docstrings from different languages
	const docstringPatterns = [
		// JSDoc: /** ... */
		/\/\*\*\s*\n?\s*\*?\s*([^@*][^\n*]+)/,
		// Python docstring: """...""" or '''...'''
		/^(?:def|class)\s+\w+[^:]*:\s*(?:"""([^"]+)"""|'''([^']+)''')/m,
		// Single line comment describing function: // description
		/^(?:export\s+)?(?:async\s+)?function\s+\w+[^{]*\{\s*\/\/\s*(.+)/m,
		// TypeScript/JS: function with preceding comment
		/\/\/\s*([A-Z][^.\n]{10,80}\.?)\s*\n(?:export\s+)?(?:async\s+)?function/,
	];

	// Regex to extract function/class name
	const namePatterns = [
		/(?:export\s+)?(?:async\s+)?function\s+(\w+)/,
		/(?:export\s+)?class\s+(\w+)/,
		/(?:export\s+)?const\s+(\w+)\s*=\s*(?:async\s*)?\(/,
		/def\s+(\w+)\s*\(/,
		/class\s+(\w+)/,
	];

	for (const { content, fileName } of chunksWithFiles) {
		// Try to extract docstring
		let docstring: string | null = null;
		for (const pattern of docstringPatterns) {
			const match = content.match(pattern);
			if (match) {
				docstring = (match[1] || match[2] || "").trim();
				break;
			}
		}

		// Try to extract name
		let funcName: string | null = null;
		for (const pattern of namePatterns) {
			const match = content.match(pattern);
			if (match) {
				funcName = match[1];
				break;
			}
		}

		// Create queries from docstrings (semantic category)
		if (docstring && docstring.length > 15 && docstring.length < 200 && fileName) {
			// Clean up docstring
			const cleanDoc = docstring
				.replace(/\s+/g, " ")
				.replace(/^[\s*-]+/, "")
				.trim();

			if (!seenQueries.has(cleanDoc.toLowerCase())) {
				seenQueries.add(cleanDoc.toLowerCase());
				queries.push({
					query: cleanDoc,
					category: "semantic",
					expected: [{ file: fileName, relevance: 3 }],
					description: `Docstring: ${funcName || "unknown"}`,
				});
			}
		}

		// Create queries from function names (keyword category)
		if (funcName && funcName.length > 3 && fileName && !seenQueries.has(funcName.toLowerCase())) {
			seenQueries.add(funcName.toLowerCase());

			// Convert camelCase/snake_case to words for better semantic search
			const words = funcName
				.replace(/([a-z])([A-Z])/g, "$1 $2")
				.replace(/_/g, " ")
				.toLowerCase();

			queries.push({
				query: `${funcName} function`,
				category: "keyword",
				expected: [{ file: fileName, relevance: 3 }],
				description: `Function: ${funcName}`,
			});

			// Also add semantic version if it produces meaningful words
			if (words.split(" ").length >= 2) {
				queries.push({
					query: words,
					category: "semantic",
					expected: [{ file: fileName, relevance: 3 }],
					description: `Semantic: ${funcName}`,
				});
			}
		}
	}

	// Limit to reasonable number (too many makes test slow)
	const maxQueries = 30;
	if (queries.length > maxQueries) {
		// Shuffle and take first N, ensuring mix of categories
		const byCategory = new Map<QueryCategory, TestQuery[]>();
		for (const q of queries) {
			if (!byCategory.has(q.category)) {
				byCategory.set(q.category, []);
			}
			byCategory.get(q.category)!.push(q);
		}

		const selected: TestQuery[] = [];
		const perCategory = Math.ceil(maxQueries / byCategory.size);
		for (const [_, catQueries] of byCategory) {
			// Shuffle
			for (let i = catQueries.length - 1; i > 0; i--) {
				const j = Math.floor(Math.random() * (i + 1));
				[catQueries[i], catQueries[j]] = [catQueries[j], catQueries[i]];
			}
			selected.push(...catQueries.slice(0, perCategory));
		}
		return selected.slice(0, maxQueries);
	}

	return queries;
}

// ============================================================================
// Symbol Graph Commands (for AI Agents)
// ============================================================================

/**
 * Format a symbol for raw output
 */
function formatSymbolRaw(symbol: {
	id?: string;
	name: string;
	kind: string;
	filePath: string;
	startLine: number;
	endLine: number;
	signature?: string;
	docstring?: string;
	isExported?: boolean;
	pagerankScore?: number;
}): string {
	const lines = [
		`file: ${symbol.filePath}`,
		`line: ${symbol.startLine}-${symbol.endLine}`,
		`kind: ${symbol.kind}`,
		`name: ${symbol.name}`,
	];
	if (symbol.signature) lines.push(`signature: ${symbol.signature}`);
	if (symbol.pagerankScore !== undefined) lines.push(`pagerank: ${symbol.pagerankScore.toFixed(4)}`);
	if (symbol.isExported !== undefined) lines.push(`exported: ${symbol.isExported}`);
	if (symbol.docstring) lines.push(`docstring: ${symbol.docstring.split('\n')[0]}`);
	return lines.join('\n');
}

/**
 * Get file tracker for a project path
 */
function getFileTracker(projectPath: string): FileTracker | null {
	const claudememDir = join(projectPath, ".claudemem");
	const dbPath = join(claudememDir, "index.db");

	if (!existsSync(dbPath)) {
		return null;
	}

	return new FileTracker(dbPath, projectPath);
}

/**
 * Handle 'map' command - generate repo map
 */
async function handleMap(args: string[]): Promise<void> {
	const raw = args.includes("--raw");

	// Parse --tokens flag
	let maxTokens = 2000;
	const tokensIdx = args.findIndex(a => a === "--tokens");
	if (tokensIdx !== -1 && args[tokensIdx + 1]) {
		maxTokens = parseInt(args[tokensIdx + 1], 10) || 2000;
	}

	// Parse --path flag for project path
	let projectPath = ".";
	const pathIdx = args.findIndex(a => a === "--path" || a === "-p");
	if (pathIdx !== -1 && args[pathIdx + 1]) {
		projectPath = args[pathIdx + 1];
	}
	projectPath = resolve(projectPath);

	// Get query (first non-flag argument)
	const nonFlagArgs = args.filter(a => !a.startsWith("-"));
	// Skip args that are values for flags
	const flagValues = new Set<string>();
	if (tokensIdx !== -1 && args[tokensIdx + 1]) flagValues.add(args[tokensIdx + 1]);
	if (pathIdx !== -1 && args[pathIdx + 1]) flagValues.add(args[pathIdx + 1]);
	const query = nonFlagArgs.find(a => !flagValues.has(a));

	const tracker = getFileTracker(projectPath);
	if (!tracker) {
		console.error("No index found. Run 'claudemem index' first.");
		process.exit(1);
	}

	try {
		const repoMapGen = createRepoMapGenerator(tracker);

		let output: string;
		if (query) {
			output = repoMapGen.generateForQuery(query, { maxTokens });
		} else {
			output = repoMapGen.generate({ maxTokens });
		}

		if (raw) {
			// Convert to raw format
			const structured = repoMapGen.generateStructured({ maxTokens: maxTokens * 2 });
			const rawOutput = structured.map(entry => {
				return entry.symbols.map(sym => [
					`file: ${entry.filePath}`,
					`line: ${sym.line}`,
					`kind: ${sym.kind}`,
					`name: ${sym.name}`,
					sym.signature ? `signature: ${sym.signature}` : null,
					`pagerank: ${sym.pagerankScore.toFixed(4)}`,
				].filter(Boolean).join('\n')).join('\n---\n');
			}).join('\n---\n');
			console.log(rawOutput);
		} else {
			if (!noLogo) printLogo();
			console.log("\nğŸ“Š Repository Map\n");
			console.log(output);
		}
	} finally {
		tracker.close();
	}
}

/**
 * Handle 'symbol' command - find symbol by name
 */
async function handleSymbol(args: string[]): Promise<void> {
	const raw = args.includes("--raw");
	const projectPath = resolve(".");

	// Get symbol name
	const symbolName = args.find(a => !a.startsWith("-"));
	if (!symbolName) {
		console.error("Usage: claudemem symbol <name> [--file <hint>] [--raw]");
		process.exit(1);
	}

	// Get file hint
	let fileHint: string | undefined;
	const fileIdx = args.findIndex(a => a === "--file");
	if (fileIdx !== -1 && args[fileIdx + 1]) {
		fileHint = args[fileIdx + 1];
	}

	const tracker = getFileTracker(projectPath);
	if (!tracker) {
		console.error("No index found. Run 'claudemem index' first.");
		process.exit(1);
	}

	try {
		const graphManager = createReferenceGraphManager(tracker);
		const symbol = graphManager.findSymbol(symbolName, {
			preferExported: true,
			fileHint
		});

		if (!symbol) {
			console.error(`Symbol '${symbolName}' not found.`);
			process.exit(1);
		}

		if (raw) {
			console.log(formatSymbolRaw(symbol));
		} else {
			if (!noLogo) printLogo();
			console.log("\nğŸ” Symbol Found\n");
			console.log(`  Name:      ${symbol.name}`);
			console.log(`  Kind:      ${symbol.kind}`);
			console.log(`  File:      ${symbol.filePath}:${symbol.startLine}-${symbol.endLine}`);
			if (symbol.signature) console.log(`  Signature: ${symbol.signature}`);
			console.log(`  PageRank:  ${symbol.pagerankScore.toFixed(4)}`);
			console.log(`  Exported:  ${symbol.isExported}`);
			if (symbol.docstring) console.log(`  Docstring: ${symbol.docstring.split('\n')[0]}`);
			console.log("");
		}
	} finally {
		tracker.close();
	}
}

/**
 * Handle 'callers' command - find what calls a symbol
 */
async function handleCallers(args: string[]): Promise<void> {
	const raw = args.includes("--raw");
	const projectPath = resolve(".");

	const symbolName = args.find(a => !a.startsWith("-"));
	if (!symbolName) {
		console.error("Usage: claudemem callers <name> [--raw]");
		process.exit(1);
	}

	const tracker = getFileTracker(projectPath);
	if (!tracker) {
		console.error("No index found. Run 'claudemem index' first.");
		process.exit(1);
	}

	try {
		const graphManager = createReferenceGraphManager(tracker);
		const symbol = graphManager.findSymbol(symbolName, { preferExported: true });

		if (!symbol) {
			console.error(`Symbol '${symbolName}' not found.`);
			process.exit(1);
		}

		const callers = graphManager.getCallers(symbol.id);

		if (raw) {
			if (callers.length === 0) {
				console.log("# No callers found");
			} else {
				const output = callers.map(caller => [
					`caller: ${caller.name}`,
					`file: ${caller.filePath}`,
					`line: ${caller.startLine}`,
					`kind: ${caller.kind}`,
				].join('\n')).join('\n---\n');
				console.log(output);
			}
		} else {
			if (!noLogo) printLogo();
			console.log(`\nğŸ“ Callers of '${symbolName}'\n`);
			if (callers.length === 0) {
				console.log("  No callers found.");
			} else {
				for (const caller of callers) {
					console.log(`  ${caller.name}`);
					console.log(`     ${caller.filePath}:${caller.startLine} (${caller.kind})`);
				}
			}
			console.log("");
		}
	} finally {
		tracker.close();
	}
}

/**
 * Handle 'callees' command - find what a symbol calls
 */
async function handleCallees(args: string[]): Promise<void> {
	const raw = args.includes("--raw");
	const projectPath = resolve(".");

	const symbolName = args.find(a => !a.startsWith("-"));
	if (!symbolName) {
		console.error("Usage: claudemem callees <name> [--raw]");
		process.exit(1);
	}

	const tracker = getFileTracker(projectPath);
	if (!tracker) {
		console.error("No index found. Run 'claudemem index' first.");
		process.exit(1);
	}

	try {
		const graphManager = createReferenceGraphManager(tracker);
		const symbol = graphManager.findSymbol(symbolName, { preferExported: true });

		if (!symbol) {
			console.error(`Symbol '${symbolName}' not found.`);
			process.exit(1);
		}

		const callees = graphManager.getCallees(symbol.id);

		if (raw) {
			if (callees.length === 0) {
				console.log("# No callees found");
			} else {
				const output = callees.map(callee => [
					`callee: ${callee.name}`,
					`file: ${callee.filePath}`,
					`line: ${callee.startLine}`,
					`kind: ${callee.kind}`,
				].join('\n')).join('\n---\n');
				console.log(output);
			}
		} else {
			if (!noLogo) printLogo();
			console.log(`\nğŸ“¤ Callees of '${symbolName}'\n`);
			if (callees.length === 0) {
				console.log("  No callees found.");
			} else {
				for (const callee of callees) {
					console.log(`  ${callee.name}`);
					console.log(`     ${callee.filePath}:${callee.startLine} (${callee.kind})`);
				}
			}
			console.log("");
		}
	} finally {
		tracker.close();
	}
}

/**
 * Handle 'context' command - get full symbol context
 */
async function handleContext(args: string[]): Promise<void> {
	const raw = args.includes("--raw");
	const projectPath = resolve(".");

	const symbolName = args.find(a => !a.startsWith("-"));
	if (!symbolName) {
		console.error("Usage: claudemem context <name> [--callers N] [--callees N] [--raw]");
		process.exit(1);
	}

	// Parse limits
	let maxCallers = 10;
	let maxCallees = 15;
	const callersIdx = args.findIndex(a => a === "--callers");
	if (callersIdx !== -1 && args[callersIdx + 1]) {
		maxCallers = parseInt(args[callersIdx + 1], 10) || 10;
	}
	const calleesIdx = args.findIndex(a => a === "--callees");
	if (calleesIdx !== -1 && args[calleesIdx + 1]) {
		maxCallees = parseInt(args[calleesIdx + 1], 10) || 15;
	}

	const tracker = getFileTracker(projectPath);
	if (!tracker) {
		console.error("No index found. Run 'claudemem index' first.");
		process.exit(1);
	}

	try {
		const graphManager = createReferenceGraphManager(tracker);
		const symbol = graphManager.findSymbol(symbolName, { preferExported: true });

		if (!symbol) {
			console.error(`Symbol '${symbolName}' not found.`);
			process.exit(1);
		}

		const context = graphManager.getSymbolContext(symbol.id, {
			includeCallers: true,
			includeCallees: true,
			maxCallers,
			maxCallees,
		});

		if (raw) {
			const sections: string[] = [];

			// Symbol section
			sections.push("[symbol]");
			sections.push(formatSymbolRaw(symbol));

			// Callers section
			sections.push("[callers]");
			if (context.callers.length === 0) {
				sections.push("# No callers");
			} else {
				sections.push(context.callers.map(caller => [
					`caller: ${caller.name}`,
					`file: ${caller.filePath}`,
					`line: ${caller.startLine}`,
					`kind: ${caller.kind}`,
				].join('\n')).join('\n---\n'));
			}

			// Callees section
			sections.push("[callees]");
			if (context.callees.length === 0) {
				sections.push("# No callees");
			} else {
				sections.push(context.callees.map(callee => [
					`callee: ${callee.name}`,
					`file: ${callee.filePath}`,
					`line: ${callee.startLine}`,
					`kind: ${callee.kind}`,
				].join('\n')).join('\n---\n'));
			}

			console.log(sections.join('\n'));
		} else {
			if (!noLogo) printLogo();
			console.log(`\nğŸ”® Context for '${symbolName}'\n`);

			// Symbol
			console.log("  Symbol:");
			console.log(`    ${symbol.name} (${symbol.kind})`);
			console.log(`    ${symbol.filePath}:${symbol.startLine}-${symbol.endLine}`);
			if (symbol.signature) console.log(`    ${symbol.signature}`);

			// Callers
			console.log(`\n  Callers (${context.callers.length}):`);
			if (context.callers.length === 0) {
				console.log("    None");
			} else {
				for (const caller of context.callers) {
					console.log(`    ${caller.name} (${caller.filePath}:${caller.startLine})`);
				}
			}

			// Callees
			console.log(`\n  Callees (${context.callees.length}):`);
			if (context.callees.length === 0) {
				console.log("    None");
			} else {
				for (const callee of context.callees) {
					console.log(`    ${callee.name} (${callee.filePath}:${callee.startLine})`);
				}
			}
			console.log("");
		}
	} finally {
		tracker.close();
	}
}

// ============================================================================
// Code Analysis Commands
// ============================================================================

/**
 * Handle 'dead-code' command - find potentially dead code
 */
async function handleDeadCode(args: string[]): Promise<void> {
	const raw = args.includes("--raw");
	const projectPath = resolve(".");

	// Parse --max-pagerank flag
	let maxPageRank = 0.001;
	const prIdx = args.findIndex(a => a === "--max-pagerank");
	if (prIdx !== -1 && args[prIdx + 1]) {
		maxPageRank = parseFloat(args[prIdx + 1]) || 0.001;
	}

	// Parse --limit flag
	let limit = 50;
	const limitIdx = args.findIndex(a => a === "--limit" || a === "-n");
	if (limitIdx !== -1 && args[limitIdx + 1]) {
		limit = parseInt(args[limitIdx + 1], 10) || 50;
	}

	// Parse --include-exported flag
	const includeExported = args.includes("--include-exported");

	const tracker = getFileTracker(projectPath);
	if (!tracker) {
		console.error("No index found. Run 'claudemem index' first.");
		process.exit(1);
	}

	try {
		const { createCodeAnalyzer } = await import("./core/analysis/index.js");
		const analyzer = createCodeAnalyzer(tracker);

		const results = analyzer.findDeadCode({
			maxPageRank,
			unexportedOnly: !includeExported,
			excludeTestFiles: true,
			limit,
		});

		if (raw) {
			if (results.length === 0) {
				console.log("# No dead code found");
			} else {
				const output = results.map(r => [
					`name: ${r.symbol.name}`,
					`file: ${r.symbol.filePath}`,
					`line: ${r.symbol.startLine}-${r.symbol.endLine}`,
					`kind: ${r.symbol.kind}`,
					`pagerank: ${r.symbol.pagerankScore.toFixed(6)}`,
					`exported: ${r.symbol.isExported}`,
				].join('\n')).join('\n---\n');
				console.log(output);
			}
		} else {
			if (!noLogo) printLogo();
			console.log("\nğŸ’€ Dead Code Analysis\n");

			if (results.length === 0) {
				console.log("  No dead code found! Your codebase is clean.");
			} else {
				console.log(`  Found ${results.length} potentially dead symbol(s):\n`);
				for (const r of results) {
					console.log(`  ${r.symbol.name}`);
					console.log(`     ${r.symbol.filePath}:${r.symbol.startLine} (${r.symbol.kind})`);
					console.log(`     PageRank: ${r.symbol.pagerankScore.toFixed(6)}`);
				}
			}
			console.log("");
		}
	} finally {
		tracker.close();
	}
}

/**
 * Handle 'test-gaps' command - find untested high-importance code
 */
async function handleTestGaps(args: string[]): Promise<void> {
	const raw = args.includes("--raw");
	const projectPath = resolve(".");

	// Parse --min-pagerank flag
	let minPageRank = 0.01;
	const prIdx = args.findIndex(a => a === "--min-pagerank");
	if (prIdx !== -1 && args[prIdx + 1]) {
		minPageRank = parseFloat(args[prIdx + 1]) || 0.01;
	}

	// Parse --limit flag
	let limit = 30;
	const limitIdx = args.findIndex(a => a === "--limit" || a === "-n");
	if (limitIdx !== -1 && args[limitIdx + 1]) {
		limit = parseInt(args[limitIdx + 1], 10) || 30;
	}

	const tracker = getFileTracker(projectPath);
	if (!tracker) {
		console.error("No index found. Run 'claudemem index' first.");
		process.exit(1);
	}

	try {
		const { createCodeAnalyzer } = await import("./core/analysis/index.js");
		const analyzer = createCodeAnalyzer(tracker);

		const results = analyzer.findTestGaps({
			minPageRank,
			limit,
		});

		if (raw) {
			if (results.length === 0) {
				console.log("# No test gaps found");
			} else {
				const output = results.map(r => [
					`name: ${r.symbol.name}`,
					`file: ${r.symbol.filePath}`,
					`line: ${r.symbol.startLine}-${r.symbol.endLine}`,
					`kind: ${r.symbol.kind}`,
					`pagerank: ${r.symbol.pagerankScore.toFixed(6)}`,
					`callers: ${r.callerCount}`,
					`test_callers: ${r.testCallerCount}`,
				].join('\n')).join('\n---\n');
				console.log(output);
			}
		} else {
			if (!noLogo) printLogo();
			console.log("\nğŸ§ª Test Coverage Gaps\n");

			if (results.length === 0) {
				console.log("  No test gaps found! All important code has test coverage.");
			} else {
				console.log(`  Found ${results.length} important symbol(s) without test coverage:\n`);
				for (const r of results) {
					console.log(`  ${r.symbol.name}`);
					console.log(`     ${r.symbol.filePath}:${r.symbol.startLine} (${r.symbol.kind})`);
					console.log(`     PageRank: ${r.symbol.pagerankScore.toFixed(4)} | Callers: ${r.callerCount}`);
				}
			}
			console.log("");
		}
	} finally {
		tracker.close();
	}
}

/**
 * Handle 'impact' command - analyze change impact
 */
async function handleImpact(args: string[]): Promise<void> {
	const raw = args.includes("--raw");
	const projectPath = resolve(".");

	// Get symbol name
	const symbolName = args.find(a => !a.startsWith("-"));
	if (!symbolName) {
		console.error("Usage: claudemem impact <symbol> [--max-depth N] [--raw]");
		process.exit(1);
	}

	// Parse --max-depth flag
	let maxDepth = 10;
	const depthIdx = args.findIndex(a => a === "--max-depth");
	if (depthIdx !== -1 && args[depthIdx + 1]) {
		maxDepth = parseInt(args[depthIdx + 1], 10) || 10;
	}

	// Parse --file flag for disambiguation
	let fileHint: string | undefined;
	const fileIdx = args.findIndex(a => a === "--file");
	if (fileIdx !== -1 && args[fileIdx + 1]) {
		fileHint = args[fileIdx + 1];
	}

	const tracker = getFileTracker(projectPath);
	if (!tracker) {
		console.error("No index found. Run 'claudemem index' first.");
		process.exit(1);
	}

	try {
		const { createCodeAnalyzer } = await import("./core/analysis/index.js");
		const analyzer = createCodeAnalyzer(tracker);

		// Find the target symbol
		const target = analyzer.findSymbolForImpact(symbolName, fileHint);
		if (!target) {
			console.error(`Symbol '${symbolName}' not found.`);
			process.exit(1);
		}

		const impact = analyzer.findImpact(target.id, {
			maxDepth,
			includeTestFiles: true,
			groupByFile: true,
		});

		if (!impact) {
			console.error("Failed to analyze impact.");
			process.exit(1);
		}

		if (raw) {
			const sections: string[] = [];

			// Target section
			sections.push("[target]");
			sections.push([
				`name: ${impact.target.name}`,
				`file: ${impact.target.filePath}`,
				`line: ${impact.target.startLine}-${impact.target.endLine}`,
				`kind: ${impact.target.kind}`,
			].join('\n'));

			// Summary
			sections.push("[summary]");
			sections.push([
				`direct_callers: ${impact.directCallers.length}`,
				`total_affected: ${impact.totalAffected}`,
				`files_affected: ${impact.byFile.size}`,
			].join('\n'));

			// By file
			sections.push("[by_file]");
			for (const [filePath, results] of impact.byFile) {
				sections.push(`file: ${filePath}`);
				sections.push(`count: ${results.length}`);
				for (const r of results) {
					sections.push(`  caller: ${r.symbol.name}`);
					sections.push(`  line: ${r.symbol.startLine}`);
					sections.push(`  depth: ${r.depth}`);
					sections.push(`  ---`);
				}
			}

			console.log(sections.join('\n'));
		} else {
			if (!noLogo) printLogo();
			console.log(`\nğŸ¯ Impact Analysis for '${symbolName}'\n`);

			// Target info
			console.log("  Target:");
			console.log(`    ${impact.target.name} (${impact.target.kind})`);
			console.log(`    ${impact.target.filePath}:${impact.target.startLine}`);

			// Summary
			console.log("\n  Summary:");
			console.log(`    Direct callers: ${impact.directCallers.length}`);
			console.log(`    Total affected: ${impact.totalAffected} symbols`);
			console.log(`    Files affected: ${impact.byFile.size}`);

			// By file
			if (impact.byFile.size > 0) {
				console.log("\n  Affected Files:");
				for (const [filePath, results] of impact.byFile) {
					console.log(`\n    ğŸ“„ ${filePath} (${results.length} symbols)`);
					for (const r of results.slice(0, 5)) {
						const depthIcon = r.depth === 1 ? "â†’" : "â†’".repeat(Math.min(r.depth, 3));
						console.log(`       ${depthIcon} ${r.symbol.name}:${r.symbol.startLine} (depth ${r.depth})`);
					}
					if (results.length > 5) {
						console.log(`       ... and ${results.length - 5} more`);
					}
				}
			}
			console.log("");
		}
	} finally {
		tracker.close();
	}
}

/**
 * Handle 'watch' command - file watcher daemon
 */
async function handleWatch(args: string[]): Promise<void> {
	const projectPath = resolve(".");

	// Parse --debounce flag
	let debounceMs = 1000;
	const debounceIdx = args.findIndex(a => a === "--debounce");
	if (debounceIdx !== -1 && args[debounceIdx + 1]) {
		debounceMs = parseInt(args[debounceIdx + 1], 10) || 1000;
	}

	const tracker = getFileTracker(projectPath);
	if (!tracker) {
		console.error("No index found. Run 'claudemem index' first.");
		process.exit(1);
	}

	try {
		const { createFileWatcher } = await import("./core/watcher/file-watcher.js");
		const watcher = createFileWatcher(projectPath, debounceMs);

		if (!noLogo) printLogo();
		console.log("\nğŸ‘ï¸  Watch Mode\n");
		console.log(`  Watching for changes in: ${projectPath}`);
		console.log(`  Debounce: ${debounceMs}ms`);
		console.log("  Press Ctrl+C to stop\n");

		await watcher.start();

		// Handle shutdown
		const shutdown = () => {
			console.log("\n\n  Stopping watcher...");
			watcher.stop();
			tracker.close();
			process.exit(0);
		};

		process.on("SIGINT", shutdown);
		process.on("SIGTERM", shutdown);

		// Keep process alive
		await new Promise(() => {}); // Never resolves
	} catch (error) {
		tracker.close();
		throw error;
	}
}

/**
 * Handle 'hooks' command - git hooks management
 */
async function handleHooks(args: string[]): Promise<void> {
	const projectPath = resolve(".");
	const subcommand = args[0];

	if (!subcommand || subcommand === "help") {
		console.log(`
Usage: claudemem hooks <subcommand>

Subcommands:
  install     Install post-commit hook for auto-indexing
  uninstall   Remove the post-commit hook
  status      Check if hook is installed
`);
		return;
	}

	const { createGitHookManager } = await import("./git/hook-manager.js");
	const hookManager = createGitHookManager(projectPath);

	switch (subcommand) {
		case "install":
			try {
				await hookManager.install();
				if (!noLogo) printLogo();
				console.log("\nâœ… Git hook installed successfully!\n");
				console.log("  The post-commit hook will now auto-index changes after each commit.");
				console.log("  Location: .git/hooks/post-commit\n");
			} catch (error) {
				console.error(`Error: ${error instanceof Error ? error.message : String(error)}`);
				process.exit(1);
			}
			break;

		case "uninstall":
			try {
				await hookManager.uninstall();
				if (!noLogo) printLogo();
				console.log("\nâœ… Git hook uninstalled successfully!\n");
			} catch (error) {
				console.error(`Error: ${error instanceof Error ? error.message : String(error)}`);
				process.exit(1);
			}
			break;

		case "status":
			const status = await hookManager.status();
			if (!noLogo) printLogo();
			console.log("\nğŸ”— Git Hook Status\n");
			console.log(`  Installed: ${status.installed ? "Yes" : "No"}`);
			if (status.installed) {
				console.log(`  Hook type: ${status.hookType}`);
			}
			console.log("");
			break;

		default:
			console.error(`Unknown subcommand: ${subcommand}`);
			console.error('Run "claudemem hooks help" for usage.');
			process.exit(1);
	}
}

// ============================================================================
// AI Instructions Command
// ============================================================================

function handleAiInstructions(args: string[]): void {
	const c = {
		reset: "\x1b[0m",
		bold: "\x1b[1m",
		dim: "\x1b[2m",
		cyan: "\x1b[36m",
		green: "\x1b[38;5;78m",
		yellow: "\x1b[33m",
		orange: "\x1b[38;5;209m",
	};

	const compact = args.includes("--compact") || args.includes("-c");
	const raw = args.includes("--raw") || args.includes("-r");
	const mcp = args.includes("--mcp-format") || args.includes("-m");
	const quick = args.includes("--quick") || args.includes("-q");
	const targetArg = args.find((a) => !a.startsWith("-"));

	// No target specified - show help
	if (!targetArg) {
		if (!noLogo) printLogo();
		console.log(`\n${c.orange}${c.bold}AI AGENT INSTRUCTIONS${c.reset}\n`);
		console.log("Print instructions for AI agents using claudemem.\n");
		console.log(`${c.yellow}${c.bold}USAGE${c.reset}`);
		console.log(`  ${c.cyan}claudemem ai <target>${c.reset} [options]\n`);
		console.log(`${c.yellow}${c.bold}TARGETS${c.reset}`);
		console.log(`  ${c.green}skill${c.reset}       Full claudemem skill (all capabilities)`);
		console.log(`  ${c.green}architect${c.reset}   System design, codebase structure`);
		console.log(`  ${c.green}developer${c.reset}   Implementation, code navigation`);
		console.log(`  ${c.green}tester${c.reset}      Test coverage, quality assurance`);
		console.log(`  ${c.green}debugger${c.reset}    Error tracing, diagnostics\n`);
		console.log(`${c.yellow}${c.bold}OPTIONS${c.reset}`);
		console.log(`  ${c.cyan}-c, --compact${c.reset}       Minimal version (~50 tokens)`);
		console.log(`  ${c.cyan}-q, --quick${c.reset}         Quick reference (~30 tokens)`);
		console.log(`  ${c.cyan}-m, --mcp-format${c.reset}    MCP tools format`);
		console.log(`  ${c.cyan}-r, --raw${c.reset}           No colors (for piping)\n`);
		console.log(`${c.yellow}${c.bold}EXAMPLES${c.reset}`);
		console.log(`  ${c.dim}# Full skill document for CLAUDE.md${c.reset}`);
		console.log(`  ${c.cyan}claudemem ai skill --raw >> CLAUDE.md${c.reset}\n`);
		console.log(`  ${c.dim}# Compact skill + role for system prompt${c.reset}`);
		console.log(`  ${c.cyan}claudemem ai developer --compact --raw${c.reset}\n`);
		console.log(`  ${c.dim}# MCP tools reference${c.reset}`);
		console.log(`  ${c.cyan}claudemem ai skill -m${c.reset}\n`);
		console.log(`  ${c.dim}# Quick reference (minimal tokens)${c.reset}`);
		console.log(`  ${c.cyan}claudemem ai skill --quick${c.reset}\n`);
		return;
	}

	const target = targetArg.toLowerCase();
	let output: string;
	let title: string;

	// Handle "skill" target
	if (target === "skill") {
		if (quick) {
			output = CLAUDEMEM_QUICK_REF;
			title = "QUICK REFERENCE";
		} else if (mcp) {
			output = CLAUDEMEM_MCP_SKILL;
			title = "MCP SKILL";
		} else if (compact) {
			output = CLAUDEMEM_SKILL_COMPACT;
			title = "SKILL (COMPACT)";
		} else {
			output = CLAUDEMEM_SKILL;
			title = "SKILL";
		}
	}
	// Handle role targets
	else if (VALID_ROLES.includes(target as AgentRole)) {
		const role = target as AgentRole;
		if (compact) {
			output = getCompactSkillWithRole(role);
			title = `${role.toUpperCase()} SKILL (COMPACT)`;
		} else {
			output = getFullSkillWithRole(role);
			title = `${role.toUpperCase()} SKILL`;
		}
	}
	// Unknown target
	else {
		console.error(`Error: Unknown target "${targetArg}"`);
		console.error(`Valid targets: skill, ${VALID_ROLES.join(", ")}`);
		process.exit(1);
	}

	// Output
	if (raw) {
		console.log(output);
	} else {
		if (!noLogo) printLogo();
		console.log(`\n${c.orange}${c.bold}${title}${c.reset}`);
		console.log(`${c.dim}${"â”€".repeat(60)}${c.reset}\n`);
		console.log(output);
		console.log(`\n${c.dim}${"â”€".repeat(60)}${c.reset}`);
		console.log(`${c.dim}Use --raw for clipboard: claudemem ai ${target} --raw | pbcopy${c.reset}\n`);
	}
}

function printHelp(): void {
	// Colors (matching claudish style)
	const c = {
		reset: "\x1b[0m",
		bold: "\x1b[1m",
		dim: "\x1b[2m",
		cyan: "\x1b[36m",
		green: "\x1b[38;5;78m",  // Softer green (not acid)
		yellow: "\x1b[33m",
		blue: "\x1b[34m",
		magenta: "\x1b[35m",
		orange: "\x1b[38;5;209m",  // Salmon/orange like claudish
		gray: "\x1b[90m",
	};

	// ASCII art logo (claudish style)
	console.log(`
${c.orange}   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—${c.reset}${c.green}â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—${c.reset}
${c.orange}  â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•${c.reset}${c.green}â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘${c.reset}
${c.orange}  â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  ${c.reset}${c.green}â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘${c.reset}
${c.orange}  â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  ${c.reset}${c.green}â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘${c.reset}
${c.orange}  â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—${c.reset}${c.green}â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘${c.reset}
${c.orange}   â•šâ•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•${c.reset}${c.green}â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•     â•šâ•â•${c.reset}

${c.bold}  Local Code Indexing.${c.reset} ${c.green}For Claude Code.${c.reset}
${c.dim}  Semantic search powered by embeddings via OpenRouter${c.reset}

${c.yellow}${c.bold}USAGE${c.reset}
  ${c.cyan}claudemem${c.reset} <command> [options]

${c.yellow}${c.bold}SERVER MODES${c.reset}
  ${c.cyan}claudemem --mcp${c.reset}                         Run MCP server for Claude Code
  ${c.cyan}claudemem --autocomplete-server${c.reset}         Run JSONL autocomplete server (editors)
  ${c.cyan}  --project${c.reset} <path>                      Project path (default: cwd)

${c.yellow}${c.bold}COMMANDS${c.reset}
  ${c.green}index${c.reset} [path]           Index a codebase (default: current directory)
  ${c.green}search${c.reset} <query>         Search indexed code ${c.dim}(auto-indexes changes)${c.reset}
  ${c.green}status${c.reset} [path]          Show index status
  ${c.green}clear${c.reset} [path]           Clear the index
  ${c.green}init${c.reset}                   Interactive setup wizard
  ${c.green}models${c.reset}                 List available embedding models
  ${c.green}benchmark${c.reset}              Compare embedding models (index, search quality, cost)
  ${c.green}benchmark-llm${c.reset}          Compare LLM models for summary generation quality
  ${c.green}benchmark-llm-v2${c.reset}       Comprehensive LLM evaluation (4 methods, resumable)
  ${c.green}benchmark-list${c.reset}         List all benchmark runs
  ${c.green}benchmark-show${c.reset}         Show results for a specific run
  ${c.green}ai${c.reset} <role>             Print AI agent instructions (architect|developer|tester|debugger)

${c.yellow}${c.bold}SYMBOL GRAPH COMMANDS${c.reset} ${c.dim}(for AI agents - use --raw for parsing)${c.reset}
  ${c.green}map${c.reset} [query]            Get repo structure ${c.dim}(optionally filtered by query)${c.reset}
  ${c.green}symbol${c.reset} <name>          Find symbol definition
  ${c.green}callers${c.reset} <name>         Find what calls a symbol
  ${c.green}callees${c.reset} <name>         Find what a symbol calls
  ${c.green}context${c.reset} <name>         Get symbol with its callers and callees

${c.yellow}${c.bold}CODE ANALYSIS COMMANDS${c.reset}
  ${c.green}dead-code${c.reset}              Find potentially dead code ${c.dim}(zero callers + low PageRank)${c.reset}
  ${c.green}test-gaps${c.reset}              Find important code without test coverage
  ${c.green}impact${c.reset} <symbol>        Analyze change impact ${c.dim}(transitive callers)${c.reset}

${c.yellow}${c.bold}DEVELOPER EXPERIENCE${c.reset}
  ${c.green}watch${c.reset}                  Watch for changes and auto-reindex ${c.dim}(daemon mode)${c.reset}
  ${c.green}hooks${c.reset} <subcommand>     Manage git hooks ${c.dim}(install|uninstall|status)${c.reset}

${c.yellow}${c.bold}INDEX OPTIONS${c.reset}
  ${c.cyan}-f, --force${c.reset}            Force re-index all files
  ${c.cyan}--no-llm${c.reset}               Disable LLM enrichment (summaries, idioms, etc.)

${c.yellow}${c.bold}SEARCH OPTIONS${c.reset}
  ${c.cyan}-n, --limit${c.reset} <n>        Maximum results (default: 10)
  ${c.cyan}-l, --language${c.reset} <lang>  Filter by programming language
  ${c.cyan}-p, --path${c.reset} <path>      Project path (default: current directory)
  ${c.cyan}-y, --yes${c.reset}              Auto-create index if missing (no prompt)
  ${c.cyan}--no-reindex${c.reset}           Skip auto-reindexing changed files
  ${c.cyan}--use-case${c.reset} <case>      Search preset: fim | search | navigation (default: search)
  ${c.cyan}-k, --keyword${c.reset}          Keyword-only search (skip embedding, use BM25 only)

${c.yellow}${c.bold}MODELS OPTIONS${c.reset}
  ${c.cyan}--free${c.reset}                 Show only free models
  ${c.cyan}--refresh${c.reset}              Force refresh from API
  ${c.cyan}--ollama${c.reset}               Show Ollama local models

${c.yellow}${c.bold}BENCHMARK OPTIONS${c.reset} ${c.dim}(embedding benchmark)${c.reset}
  ${c.cyan}--models=${c.reset}<list>        Comma-separated model IDs to test
  ${c.cyan}--real${c.reset}                 Use 100 chunks (default: 50)
  ${c.cyan}--auto${c.reset}                 Auto-generate queries from docstrings (any codebase)
  ${c.cyan}--verbose${c.reset}              Show detailed per-query results

${c.yellow}${c.bold}BENCHMARK-LLM OPTIONS${c.reset} ${c.dim}(LLM summary benchmark)${c.reset}
  ${c.cyan}--generators=${c.reset}<list>    LLM providers/models to test (comma-separated)
                          ${c.dim}Formats: provider | provider/model${c.reset}
                          ${c.dim}Examples: cc/opus, cc/sonnet, cc/haiku, openrouter/openai/gpt-4o${c.reset}
                          ${c.dim}Providers: cc (Claude Code), anthropic, openrouter, local/ollama/lmstudio${c.reset}
  ${c.cyan}--verbose${c.reset}, ${c.cyan}-v${c.reset}           Show detailed error messages during benchmark
  ${c.cyan}--judges=${c.reset}<list>        LLM models to judge quality ${c.dim}(optional, enables blind eval)${c.reset}
  ${c.cyan}--cases=${c.reset}<n|all>        Number of test cases or "all" for entire codebase ${c.dim}(default: 10)${c.reset}
  ${c.cyan}--format=${c.reset}<fmt>         Output format: cli | json | detailed ${c.dim}(default: cli)${c.reset}

${c.yellow}${c.bold}BENCHMARK-LLM-V2 OPTIONS${c.reset} ${c.dim}(comprehensive LLM evaluation)${c.reset}
  ${c.cyan}--generators=${c.reset}<list>    LLM providers/models to test (comma-separated)
  ${c.cyan}--judges=${c.reset}<list>        LLM models for LLM-as-Judge evaluation
  ${c.cyan}--cases=${c.reset}<n|all>        Target code units (default: 100)
  ${c.cyan}--resume=${c.reset}<run-id>      Resume from previous run
  ${c.cyan}--local-parallelism=${c.reset}<n> Local models parallelism (1=seq, 2-4, all) ${c.dim}(default: 1)${c.reset}
  ${c.cyan}--verbose${c.reset}, ${c.cyan}-v${c.reset}           Show detailed progress
  ${c.dim}Evaluation methods: LLM-as-Judge, Contrastive, Retrieval (P@K/MRR), Downstream${c.reset}
  ${c.dim}Outputs: JSON, Markdown, HTML reports${c.reset}

${c.yellow}${c.bold}SYMBOL GRAPH OPTIONS${c.reset}
  ${c.cyan}--raw${c.reset}                  Machine-readable output (line-based, for parsing)
  ${c.cyan}--tokens${c.reset} <n>           Max tokens for map output (default: 2000)
  ${c.cyan}--file${c.reset} <hint>          Disambiguate symbol by file path
  ${c.cyan}--callers${c.reset} <n>          Max callers to show (default: 10)
  ${c.cyan}--callees${c.reset} <n>          Max callees to show (default: 15)

${c.yellow}${c.bold}CODE ANALYSIS OPTIONS${c.reset}
  ${c.cyan}--max-pagerank${c.reset} <n>     Dead-code threshold (default: 0.001)
  ${c.cyan}--min-pagerank${c.reset} <n>     Test-gaps threshold (default: 0.01)
  ${c.cyan}--max-depth${c.reset} <n>        Impact analysis depth (default: 10)
  ${c.cyan}--include-exported${c.reset}     Include exported symbols in dead-code scan
  ${c.cyan}-n, --limit${c.reset} <n>        Max results (default: 50 for dead-code, 30 for test-gaps)

${c.yellow}${c.bold}WATCH/HOOKS OPTIONS${c.reset}
  ${c.cyan}--debounce${c.reset} <ms>        Watch debounce time (default: 1000ms)

${c.yellow}${c.bold}AI OPTIONS${c.reset}
  ${c.cyan}-c, --compact${c.reset}          Minimal version (~50 tokens)
  ${c.cyan}-q, --quick${c.reset}            Quick reference (~30 tokens)
  ${c.cyan}-m, --mcp-format${c.reset}       MCP tools format
  ${c.cyan}-r, --raw${c.reset}              No colors (for piping)

${c.yellow}${c.bold}GLOBAL OPTIONS${c.reset}
  ${c.cyan}-v, --version${c.reset}          Show version
  ${c.cyan}-h, --help${c.reset}             Show this help
  ${c.cyan}--nologo${c.reset}               Suppress ASCII logo (for scripts/agents)
  ${c.cyan}--models${c.reset}               List available embedding models (with --free, --refresh)

${c.yellow}${c.bold}MCP SERVER${c.reset}
  ${c.cyan}claudemem --mcp${c.reset}        Start as MCP server (for Claude Code)

${c.yellow}${c.bold}ENVIRONMENT${c.reset}
  ${c.magenta}OPENROUTER_API_KEY${c.reset}     API key for embeddings
  ${c.magenta}ANTHROPIC_API_KEY${c.reset}      API key for LLM enrichment (Anthropic provider)
  ${c.magenta}CLAUDEMEM_MODEL${c.reset}        Override default embedding model
  ${c.magenta}CLAUDEMEM_LLM${c.reset}          LLM spec (e.g., "a/sonnet", "or/openai/gpt-4o", "cc/haiku")

${c.yellow}${c.bold}EXAMPLES${c.reset}
  ${c.dim}# First time setup${c.reset}
  ${c.cyan}claudemem init${c.reset}

  ${c.dim}# Index current project${c.reset}
  ${c.cyan}claudemem index${c.reset}

  ${c.dim}# Index without LLM enrichment (faster, code-only)${c.reset}
  ${c.cyan}claudemem index --no-llm${c.reset}

  ${c.dim}# Search (auto-indexes changes)${c.reset}
  ${c.cyan}claudemem search "authentication flow"${c.reset}
  ${c.cyan}claudemem search "error handling" -n 5${c.reset}

  ${c.dim}# Search without auto-reindex${c.reset}
  ${c.cyan}claudemem search "query" --no-reindex${c.reset}

  ${c.dim}# Auto-create index on first search${c.reset}
  ${c.cyan}claudemem search "something" -y${c.reset}

  ${c.dim}# Show available embedding models${c.reset}
  ${c.cyan}claudemem --models${c.reset}
  ${c.cyan}claudemem --models --free${c.reset}

  ${c.dim}# Benchmark embedding models (index speed, search quality, cost)${c.reset}
  ${c.cyan}claudemem benchmark${c.reset}
  ${c.cyan}claudemem benchmark --auto${c.reset}  ${c.dim}# works on any codebase${c.reset}
  ${c.cyan}claudemem benchmark --models=qwen/qwen3-embedding-8b,openai/text-embedding-3-small${c.reset}

  ${c.dim}# Get AI agent instructions${c.reset}
  ${c.cyan}claudemem ai${c.reset}                          ${c.dim}# show help${c.reset}
  ${c.cyan}claudemem ai skill${c.reset}                    ${c.dim}# full skill document${c.reset}
  ${c.cyan}claudemem ai skill --raw >> CLAUDE.md${c.reset} ${c.dim}# append to CLAUDE.md${c.reset}
  ${c.cyan}claudemem ai developer --compact${c.reset}      ${c.dim}# role + skill (minimal)${c.reset}

  ${c.dim}# Symbol graph commands (for AI agents)${c.reset}
  ${c.cyan}claudemem --nologo map --raw${c.reset}                      ${c.dim}# repo structure${c.reset}
  ${c.cyan}claudemem --nologo map "auth" --raw${c.reset}               ${c.dim}# focused on query${c.reset}
  ${c.cyan}claudemem --nologo symbol Indexer --raw${c.reset}           ${c.dim}# find symbol${c.reset}
  ${c.cyan}claudemem --nologo callers VectorStore --raw${c.reset}      ${c.dim}# what uses it?${c.reset}
  ${c.cyan}claudemem --nologo callees VectorStore --raw${c.reset}      ${c.dim}# what it uses?${c.reset}
  ${c.cyan}claudemem --nologo context VectorStore --raw${c.reset}      ${c.dim}# full context${c.reset}

  ${c.dim}# Code analysis commands${c.reset}
  ${c.cyan}claudemem dead-code${c.reset}                               ${c.dim}# find dead code${c.reset}
  ${c.cyan}claudemem test-gaps${c.reset}                               ${c.dim}# find untested code${c.reset}
  ${c.cyan}claudemem impact createIndexer${c.reset}                    ${c.dim}# change impact analysis${c.reset}

  ${c.dim}# Developer experience${c.reset}
  ${c.cyan}claudemem watch${c.reset}                                   ${c.dim}# auto-reindex on changes${c.reset}
  ${c.cyan}claudemem hooks install${c.reset}                           ${c.dim}# install git hook${c.reset}

${c.yellow}${c.bold}MORE INFO${c.reset}
  ${c.blue}https://github.com/MadAppGang/claudemem${c.reset}
`);
}

// ============================================================================
// Benchmark LLM V2 Handler
// ============================================================================

async function handleBenchmarkLLMv2(args: string[]): Promise<void> {
	const { runBenchmarkCLI } = await import("./benchmark-v2/index.js");
	await runBenchmarkCLI(args);
}

// ============================================================================
// Benchmark List/Show Handlers
// ============================================================================

async function handleBenchmarkList(args: string[]): Promise<void> {
	const { BenchmarkDatabase } = await import("./benchmark-v2/storage/benchmark-db.js");

	// Colors for output
	const c = {
		reset: "\x1b[0m",
		bold: "\x1b[1m",
		dim: "\x1b[2m",
		cyan: "\x1b[36m",
		green: "\x1b[38;5;78m",
		yellow: "\x1b[33m",
		red: "\x1b[31m",
	};

	// Parse arguments
	const limitArg = parseInt(args.find(a => a.startsWith("--limit="))?.split("=")[1] || "20", 10);
	const statusFilter = args.find(a => a.startsWith("--status="))?.split("=")[1] as "completed" | "failed" | "running" | undefined;
	const projectPath = args.find(a => a.startsWith("--project="))?.split("=")[1] || process.cwd();

	const dbPath = join(projectPath, ".claudemem", "benchmark-v2.db");
	if (!existsSync(dbPath)) {
		console.log(`${c.yellow}No benchmark database found at ${dbPath}${c.reset}`);
		console.log(`${c.dim}Run benchmarks first with: claudemem benchmark ...${c.reset}`);
		return;
	}

	const db = new BenchmarkDatabase(dbPath);
	const runs = db.listRuns(statusFilter).slice(0, limitArg);

	if (runs.length === 0) {
		console.log(`${c.yellow}No benchmark runs found${c.reset}`);
		return;
	}

	console.log(`\n${c.cyan}ğŸ“Š Benchmark Runs${c.reset} (${runs.length} shown)\n`);
	console.log(`${"ID".padEnd(38)} ${"Status".padEnd(10)} ${"Date".padEnd(20)} ${"Models".padEnd(8)} ${"Cases".padEnd(6)} Project`);
	console.log(`${"â”€".repeat(38)} ${"â”€".repeat(10)} ${"â”€".repeat(20)} ${"â”€".repeat(8)} ${"â”€".repeat(6)} ${"â”€".repeat(30)}`);

	for (const run of runs) {
		const date = new Date(run.startedAt).toLocaleString();
		const statusColor = run.status === "completed" ? c.green : run.status === "failed" ? c.red : c.yellow;
		const modelCount = run.config.generators.length;
		const caseCount = run.config.sampleSize;
		const project = run.config.projectPath.split("/").pop() || run.config.projectPath;

		console.log(
			`${c.dim}${run.id.slice(0, 36)}${c.reset} ` +
			`${statusColor}${run.status.padEnd(10)}${c.reset} ` +
			`${date.padEnd(20)} ` +
			`${String(modelCount).padEnd(8)} ` +
			`${String(caseCount).padEnd(6)} ` +
			`${project}`
		);
	}

	console.log(`\n${c.dim}Use: claudemem benchmark-show <run-id> to view results${c.reset}\n`);
}

async function handleBenchmarkShow(args: string[]): Promise<void> {
	const { BenchmarkDatabase } = await import("./benchmark-v2/storage/benchmark-db.js");
	const { displayBenchmarkResults } = await import("./benchmark-v2/display.js");

	// Colors for output
	const c = {
		reset: "\x1b[0m",
		bold: "\x1b[1m",
		dim: "\x1b[2m",
		cyan: "\x1b[36m",
		green: "\x1b[38;5;78m",
		yellow: "\x1b[33m",
		red: "\x1b[31m",
	};

	const runId = args.find(a => !a.startsWith("--"));
	if (!runId) {
		console.log(`${c.red}Error: Please provide a run ID${c.reset}`);
		console.log(`Usage: claudemem benchmark-show <run-id>`);
		console.log(`       claudemem benchmark-show <run-id> --json`);
		console.log(`       claudemem benchmark-show <run-id> --project=/path/to/project`);
		return;
	}

	const projectPath = args.find(a => a.startsWith("--project="))?.split("=")[1] || process.cwd();
	const dbPath = join(projectPath, ".claudemem", "benchmark-v2.db");
	if (!existsSync(dbPath)) {
		console.log(`${c.yellow}No benchmark database found at ${dbPath}${c.reset}`);
		return;
	}

	const db = new BenchmarkDatabase(dbPath);
	const run = db.getRun(runId);

	if (!run) {
		console.log(`${c.red}Error: Run not found: ${runId}${c.reset}`);
		return;
	}

	const jsonOutput = args.includes("--json");

	if (jsonOutput) {
		const scores = db.getAggregatedScores(runId);
		console.log(JSON.stringify({
			run: {
				id: run.id,
				status: run.status,
				startedAt: run.startedAt,
				config: run.config,
			},
			scores: Object.fromEntries(scores),
		}, null, 2));
		return;
	}

	// Display run info header
	console.log(`\n${c.cyan}ğŸ“Š Benchmark Run: ${run.id}${c.reset}\n`);
	console.log(`Status:     ${run.status === "completed" ? c.green : c.red}${run.status}${c.reset}`);
	console.log(`Started:    ${new Date(run.startedAt).toLocaleString()}`);
	console.log(`Project:    ${run.config.projectPath}`);
	console.log(`Cases:      ${run.config.sampleSize}`);
	console.log();

	// Use the full display function (same as after benchmark run)
	const generatorSpecs = run.config.generators.map(g => g.id);
	const judgeModels = run.config.judges;

	await displayBenchmarkResults(db, runId, generatorSpecs, judgeModels);
}
